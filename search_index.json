[
["index.html", "経済動学: 線形編 序文 構成 謝辞", " 経済動学: 線形編 佐藤 健治 2017-03-02 序文 このノートは, 神戸大学大学院経済学研究科で2016年度, 2017年度の第1クォーターに実施した講義に基づいている. マクロ経済学, マクロ計量経済学, および数理経済学を専攻しようとする院生を読者として想定しているが, 数学的な議論が苦にならなければ学部上級の学生にとっても有益なものと思われる. 線形代数学, 動的システム理論, 力学系の初歩的な概念からはじめて, できるかぎり自己完結的なものとなるように心がけたので, マクロ経済学に特化した「経済数学」の参考書という使いかたもできると思う. また, 経済学に関する既知の事実をほとんど利用しないので, 経済モデルの分析に関心を持ち始めた理学・工学系の学生にとっても有用だろう. この講義では, 線形合理的期待モデルの分析を中心的な課題としている. 次の3つを中心的な課題としている. 線形合理的期待モデルの理論分析 その計算機シミュレーション マルコフスイッチング合理的期待モデルの紹介 マクロ数量分析の標準的なツールである Dynare を自分で使ったり, 名前を聞いたことのある学生も多いと思う. 一方で, その裏側でどのような計算が行われているかを知らないという学生も多いのではないかと思う. 理論に無関心でもおおよそ問題が起こらないのは, ひとえに Dynare が優れたインターフェイスを備えたアプリケーションであるということに外ならないのだが, そのブラックボックスを開けて理論を理解しようというのがこの講義の第1の課題である. 第2の課題は, 読者にコンピュータシミュレーションの基礎的な手法を身につけてもらうことである. 線形合理的期待モデルは近年のマクロ経済の数量分析に大きな役割を果たしているから, 各自の研究プロジェクトに大いに役に立つものと信じている. 数学もプログラミングも自分の手を動かし, 頭を悩ませなければ習熟できない. 理論とその実装を行き来しながら総合的な問題解決能力を養ってほしい. この講義では, 主に R言語を用いる.1 最後に, 近年盛んに研究されているマルコフスイッチング合理的期待モデルという非線形モデルを紹介する. 線形モデルのように, (ある種の) 安定性・不安定性に関する必要十分条件が得られるという特徴があり, 理論的に扱いやすい. 金融政策ルールに関するテイラーの条件を緩和できることが知られており, 理論・実証の両面から盛んに研究が進んでいる分野である. 構成 本書は15回 (週2回, 各回90分 × 8週) のクォーター制の講義に合わせて作られている. 原則的には各回1章を順に読み進めていくように構成している. 随所に理解を試す「練習問題」を設けたので, すべての問題に取り組んでほしい. 最初の数章は動的システムの分析に必要な, 学部初年次に習うであろう定義と結果をまとめているだけなので, 多くの読者にとって既知の事柄の羅列になっているはずだ. したがって, 練習問題を解いてみて躓くことがなければ読み飛ばすことができる. ただし, 各章は段階的に難しくなるように配置されているので, 少しでも不安があるようなら一読をお薦めする. また, この分野をすでに知っている読者でなければ関心のある章だけを読むという使い方はできないと思う. 第1章: はじめに どのようなモデルを解きたいか プログラミング環境の構築 第2章: 複素数 複素数の復習 なぜ複素数が必要なのか 第3章: 行列論の基礎 行列の復習 行列積と複素数積の類似性 第4章: 行列の固有値 行列の固有値の復習 線形システム複素固有値の関係を明らかにする 第5章: 固有空間 第6章: ジョルダン標準形と線形システムの安定性 ジョルダン標準形 安定性 第7章: \\(\\det A \\neq 0\\) Blanchard and Kahn (1980) 第8章: ワイエルシュトラス標準形とデスクリプタシステム \\(\\det A = 0\\) 第9章: 一般の \\(A\\) Stock and Watson? 第10章: 数値解法 Schur 分解 QZ 分解 第11章: Klein の方法 Klein (2000) 第12章: Sims の方法 第13章: 確率システム 第14章: Lubik-Schorfheide 第15章: マルコフスイッチングシステム 謝辞 コロンビア大学の安東宇さんから有益なコメントをいくつかいただいた. 参考文献 "],
["intro.html", "第1章 はじめに 1.1 経済動学 1.2 対象とするモデル 1.3 プログラミング環境", " 第1章 はじめに 1.1 経済動学 「経済動学」（economic dynamics）では経済の状態を表す変数（経済指標）の時間を通じた変化， あるいは変化の不在，を研究する。どのような問題を扱おうとしているのか整理しておこう。 学部レベルのミクロ経済学を履修した読者は次のような最適化問題には馴染みがあると思う。 \\[ \\begin{aligned} &amp;\\max_{c\\in \\mathbb{R}^N_+} u(c) \\\\ &amp;\\text{subject to}\\quad p \\cdot c \\le I \\end{aligned} \\] 価格 \\(p = (p_1, \\dots, p_N)\\) と所得 \\(I\\) のもとで，効用 \\(u(c)\\) を最大にする消費量の組み合わせ \\(c = (c_1, \\dots, c_N)\\) を選べという問題である。この消費者モデルに対する標準的な仮定は，経済には\\(N\\) 種の異なる財があり，そのうちの第 \\(n\\) 財, \\(n = 1, \\dots, N\\), には価格 \\(p_n\\) が設定されている。 消費者はそれを \\(c_n\\) 単位購入する。すべての財を購入するには，\\(p\\cdot c = \\sum_{n = 1}^N p_n x_n\\) を支払う必要があるが，所得 \\(I\\) を超える支出はできない。 各財を並べた順番 \\(n = 1, \\dots, N\\) は完全に任意である。 \\(c_n\\) と \\(c_{n + 1}\\) がそのように並んでいることには何の理由もない。したがって，例えば， \\(c_1 &lt; c_2 &lt; c_3 &lt; \\cdots\\) という単調性（monotonicity）が得られたとしても， たまたまそのようになったという以上の解釈はできない。 モデルを変えずに，解釈を変更してみよう。経済には本質的には1つの財しかないとする。 例えば\\(c_1\\) は2001年の消費，\\(c_2\\) を2002年の消費という様に， 各 \\(c_n\\) をある特定の時点における経済活動を表す変数と解釈する。このような解釈の変更は， 解くべきモデルを変えることなく結果の解釈を変える。すなわち，先程の単調性は， 年々消費が増えていくということを意味している。説明上，\\(N\\) を有限としたが，\\(N = \\infty\\) のケースを考えることが多い。\\(N\\) が有限のとき， そのモデルは有限ホライズン（finite horizon）のモデルであるといい， そうでないとき無限ホライズン（infinite horizon）であるという。 各変数が時間によってラベル付けされたモデルを解き， その解が満たす経時的な性質を調べるのが経済動学の主要な課題である。 次のような命題に関心がある。 時間を通じて一定であるか，あるいは，十分時間が経てば収束状態に落ち着くか。 それとも，発散や恒常的な振動経路が観測されるか。 収束経路は単調に増加（あるいは減少）するか，それとも振動的か。 恒常的な振動が観測さるケースでは，振動は規則的（周期的， periodic）かあるいは不規則的（カオス，chaos）か。 経済状態は過去の経路に依存して決まるか，それとも経路依存性はないか。 経済状態は一意的に定まるのか，あるいは経済主体の「気まぐれ」が経路を変えてしまうことがあるのか。 etc. モデルの解を特徴付ける方程式を動学方程式（dynamic equation）, あるいは動的システム（dynamic system）という。 経済学のモデルでは，消費者の効用最大化・企業の利潤最大化・種々の制約条件からなる最適化問題が満たす均衡条件として， 時点が隣り合う変数が満たす方程式を得られることが多い[^上のリストで挙げた「経路依存性」がないケースである。]。 \\[ F(x_t, x_{t + 1}) = 0, \\quad t = 1, 2, \\dots \\] ただし，\\(x_t\\) は関心のある経済変数を並べたベクトルである。時間（time）を表すインデックスを \\(t\\) に変更した。経済政策などの外的な要因（ショック，shock）で経済環境が変化するケースを扱う場合には， \\[ F(x_t, x_{t+1}, z_t) = 0 \\] といった動学方程式が得られることになる。これらのシステムは陰関数の解として変数が定まるという 意味で陰的システム（implicit system）である。 経済の経時的な変化を知るためには，\\(x_1, x_2, \\dots\\) という時系列が必要であるから， 理想的には逐次的な計算公式 \\[ x_{n + 1} = G_t (x_t, z_t) \\] が必要である。あるいは，\\(G\\) の時間依存性がなければ， \\[ x_{n+1} = G(x_t, z_t) \\] とできるかもしれない。上で例示したような動的システムは解くことができない。 1.2 対象とするモデル この講義では，次のような動的システムを考察する。 \\begin{equation} A\\mathbb{E}_{t}x_{t+1}=Bx_{t}+Cz_{t} (\\#eq:lre) \\end{equation} \\(x_t\\) はモデルを解いて決まる変数を並べたベクトル（内生変数，endogenous variable）， \\(z_t\\) はモデルの外で決まる変数（外生変数，exogenous variable）。\\(A\\), \\(B\\), \\(C\\) は適切なサイズの行列である。 \\(\\mathbb E_t\\) は条件付き期待値である。 行列積と足し算だけからなる上記のようなシステムを線形システム（linear system）という。上の線形方程式を \\begin{equation} Bx_{t} = A\\mathbb{E}_{t}x_{t+1} - Cz_{t} (\\#eq:lre2) \\end{equation} と書き換えると，今期の経済変数は将来に対する期待によって定まっていると読むことができる。 式(??) や 式(??) のようなシステムを 線形合理的期待モデル (linear rational expectations model) という。 本書ではモデルの導出に深く踏み込まないが，価格や消費といった変数は将来に対する予想を反映して (forward-looking) 決まるということだけ意識しておけば十分だろう。 予想を反映して価格が決まるという関係は次のような例を通して理解できる。 企業の株価はその企業が将来的に生み出す価値を利子率 (あるいは割引率) を考慮して割引いた値と一致するように決まる，というのが経済理論の基本公式である。 なお， 「割引」(discount) というのは収益を手にするまでに待たなければいけない時間分だけ減価調整することである。 このような関係が成立する理由は比較的容易に理解できる。 ある企業の期待収益の割引現在価値がその企業の株価総額よりも一時的に高いとしよう。 当該株式を購入すれば 長い時間を通じて購入価格よりも高い収益を得ることができるのだから， そのような株式には買い手が集まり，市場価格は上昇する。逆に， 期待収益が株価総額を一時的に下回っているとしよう。 株主は株式を手放すインセンティブを持つが，そのような市場価格では買い手はつかない。 売値を下げてでも売りたいと考える株主がいなくなるまで株価は下落するだろう。 予想した価値と市場価格の不一致が解消された結果として達成されるのが先の価格公式というわけである。 利鞘を稼ぐチャンス（裁定機会，arbitrage opportunity）が存在すれば， 市場を通じて価格が速やかに調整され，その結果として裁定機会は失われる。 経済理論は裁定機会が消滅した後の経済環境（均衡）に焦点を当てて分析を行うことが多いが， それは上のような思想に基づいている。 通常, 経済モデルは非線形システム（線形でないシステムをすべて非線形システムという） によって記述されることが多いのだが, 非確率的な平衡点 \\(x^* = x_t = x_{t+1}\\), \\(z_t = 0\\) （\\(t &gt; 0\\)）の周りに分析を限定すれば，線形システムによってよく近似されることが知られている2。 線形システムの分析は係数行列 (上記の \\(A\\)，\\(B\\)，\\(C\\)) の分析に落とし込むことができるため， 理論的にも数値的にも大変扱いやすい。したがって， これから我々が学ぶ分析手法は平衡状態にある経済に対して小さなショックが加わったときに経済変数がどのような経時的変化を示すかを分析するための第一歩である。 実際には線形近似のみから数量的なインプリケーションを導くことは困難であるから， 有用な分析を行うためには高次の近似手法を学ぶ必要がある。しかし， 線形理論を理解することなく非線形理論を理解することはできない。一歩一歩着実に進んでいこう。 1.2.1 決定論モデル 実は確率的な要因がなくなったとしても分析の基本的な方針は変わらない。すなわち， 非確率的 (決定論的) なシステム \\begin{equation} Ax_{t+1} = Bx_t + Cz_t (\\#eq:lsys) \\end{equation} を分析する手法を確立すれば，(??) の分析・シミュレーションができる。 まずは (??) の分析について述べたのち， 確率的な要因を導入するというステップで理論分析を進める。 さらに，非決定論的な分析を数段階に分けて解説する。 \\(A\\) が正則のケース 解析的手法 数値的手法 \\(A\\) が非正則のケース 解析的手法 数値的手法 \\(A\\) が正則のケースでは (??) は \\begin{equation} x_{t+1} = A^{-1}Bx_t + A^{-1}Cz_t (\\#eq:lsys) \\end{equation} と同値であるから（\\(A^{-1}\\) は \\(A\\) の逆行列）， 標準的な線形システム (状態空間方程式) と形式的には同じものである。 続いて，\\(A\\) が非正則のケースを扱う。上記の (??) は， 制御理論の分野でデスクリプタシステム（descriptor system）， あるいは陰的システム（implicit system）として知られている対象である。 この分野で研究を進めようという人は， 同じ概念が異なる分野で異なる名前で利用されていることを知っておく方がよいだろう。 ちなみに，デスクリプタシステムは「非因果的」（non-causal） なシステムを表現するために利用される。すなわち，未来の情報が現在に影響をおよぼすようなシステムである。 どこかで聞いたことのある話ではないだろうか？ 経済学における “forward-looking” は制御理論では非因果性と呼ばれている。 1.2.2 制御理論との違い ただし経済学と制御理論の扱う対象が完全に同じだという訳ではない。経済モデルは， \\(A\\)が正則であったとしても forward-looking（非因果的）な現象を表すように作られている。 力学系理論や制御理論で式(??)のようなシステムを扱うときには， 通常 \\(x\\) と同じ数だけの初期条件 (initial codition) を与える。 そのようなケースでは初期条件から出発してシステムの解を逐次的に求めることができるから， 解を求める上で特段の難しさはない。一方，経済学における forward-looking の表現は， システム方程式(??)とは独立している。 すなわち，変数（ベクトル） \\(x\\) の一部の要素に初期条件が与えられて， 残りの要素には初期条件が与えられないという形で forward-looking を扱う。 初期条件を持つ成分を先決成分 (predetermined component) とか先決変数 (predetermined variable)と呼ぶ。 初期条件を持たない成分を非先決成分 (non-predetermined component) とか非先決変数 (non-predetermined variable) と呼ぶ3。 例えば, 株式保有量を\\(a\\)，株価を\\(p\\)，株価に対する外的な影響を\\(u\\)として， ベクトル \\((a, p)\\) が次の動学方程式を満たすというモデルを作ったとしよう。 \\[ \\begin{bmatrix} a_{t+1} \\\\ p_{t+1} \\end{bmatrix} = B \\begin{bmatrix} a_{t} \\\\ p_{t} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ u_{t} \\end{bmatrix} \\] このとき \\(a_0\\) は初期値として与えられているが，\\(p_0\\) は \\(a_0\\) および \\(u\\) に対する予想に基いて決まるというのが典型的なマクロ経済学の問題である. 1.2.3 安定性と決定性 さて，一部の変数に初期条件が与えられていない問題をどのように解けばよいだろうか。 もちろん，\\(a_1, a_2, \\dots\\) や \\(p_0, p_1, \\dots\\) に対して何の制約も置かなければこのような問題を解くことはできない。 Blanchard and Kahn (1980) が提案した条件は次のようなものである。 経済主体は幾何級数よりも早いスピードで発散するような予想に基いて行動することはない。 すなわち，幾何級数より早く発散するような初期値を除いた結果，初期値を1点に定めることができれば， その点は一意の均衡である。しかし，動学方程式を満たしつつ， 安定性（非幾何的発散）を満足するような経路は一般には無数に存在する。一意的であるようなケースを 決定的 (deterinate) と呼び，決定的でないケースを 不決定的 (indeterminate) と呼ぶ。 1.2.4 合理的期待モデル 続いてシステム (??) の分析を行う. ショック項 \\(z\\) を確率過程となるが, 決定論の分析を理解していれば, 条件付き期待値の性質を少し覚えるだけで理解できるようになる. 決定論モデルと同じ安定性の概念を利用して決定性を特徴づけることができるので, 実は決定論システムと本質的な違いはない. 本書では, やや発展的な話題を紹介する. 1.2.5 マルコフスイッチングモデル 次に, 係数行列がマルコフ連鎖に従って変化するモデルに拡張する. このような拡張をすると, 伝統的な合理的期待モデルが利用してきた安定性の概念を利用することができなくなる. 二乗平均安定性 (Mean Square Stability)という安定性概念を導入し, 決定性を特徴付ける. 1.3 プログラミング環境 1.3.1 RStudio 前述のような線形モデルは (広く普及している C, Fortran のルーチンのおかげで) 大抵のプログラミング言語で解くことができる. 本書で R を使用するのは, 想定する読者層がもっとも接近しやすい言語であろうと考えたからである. 計量経済学の学習は Stata を使い, マクロ経済学では Matlab, 数理経済学の授業では Python というようなことにもなりがちだが, プログラミングの初級者は1つの言語に深く習熟するようにした方がよい. 将来的に他の言語に移るとしても, 広く浅く学んだ人よりも深く狭く学んだ人の方が, 速く学ぶ. R は計量経済学のツールとしてもとても優秀で, しかも多くのユーザーコミュニティがある. データ収集, 図示, モデリング, ドキュメント作成のすべての工程をRとRStudio で実行することができる. RStudio に触れる機会を増やすために, すべてのレポートを RStudio で作成するように気持ちを切り替えてみよう. RMarkdown という書式で書き, それをコンパイルする. knitr や pandoc がスムーズに仕事をこなしてくれる. PDF に変換するには texlive をインストールする. サイズは大きいが簡単だ. 数式を入力するには LaTeX の構文を覚える必要があるが, 大学院にいる以上いずれ必要になる技術だから, 今やっておいて損はない. RMarkdown は LaTeX そのものと比べると概ね自然に書くことができるし, 何よりも R のコードや計算結果, グラフを文章内に埋め込むのが非常に簡単だ. ところで, 本書も RStudio で書いている. いくつかの RMarkdown ファイル, 設定ファイルを bookdown というパッケージがうまく処理してくれる. R に十分習熟し, プロファイリングの努力も虚しく計算速度に限界を感じることがあるかもしれない. そうなった C++ を少し学べばよい. 重い処理だけを扱う C++ のコードを用意し, RCpp パケージを使って呼び出すことができる. そのような願望が現れるころには計算機の仕組みをある程度理解しているだろうから, C++ も速く学べると思う. 本書のコードに関する解説は, 読者が RStudio で作業をしているものと想定している. Rプログラミングの経験が浅い読者は, 筆者と同様の環境を構築しておくほうが混乱がないだろう. 本節の残りの部分で RStudio の使い方に関する簡単な説明と, 環境構築を行う. 1.3.2 準備 R 本体も RStudio もバイナリファイルをダウンロードして簡単にインストールすることができるので, インストールに関する詳細は省略する. このコースの学習用に RStudio プロジェクトファイルを用意しておこう. RStudio を起動し, メニューから「File &gt; New Project…」をクリックして新しいプロジェクトを作成する. 作成方法に関していくつかの選択肢を提示されるので, 特に問題がなければ「New Directory &gt; Empty Project」を選ぶ. 必要な入力項目を入力する. 例えば, プロジェクト名をlinear-economic-dynamics としておこう. 指定したディレクトリの配下に, linear-economic-dynamics という名前の新しいディレクトリ (フォルダ) , さらにその中に linear-economic-dynamics.Rproj というファイルが作成される. 作業再開時には, linear-economic-dynamics.Rproj をダブルクリックして, RStudio が開く. 先程作ったディレクトリが作業ディレクトリになる. プロジェクト作成直後はすでに作業ディレクトリを移っているのでそのまま進めて構わない. 次の用語を説明する. 説明できない場合は検索して調べる. ディレクトリ, フォルダ, directory, folder 作業ディレクトリ, working directory / current directory 相対パス, relative path 絶対パス, absolute path コンソール, console スクリプトファイル, script file コマンドの実行はコンソールに入力＋Enter 押下でもよいし, コマンドをスクリプトファイルに書いて実行してもよい. コンソール Console と書かれたエリアを探してほしい. 設定をいじっていなければ,4 R version 3.3.2 (2016-10-31) -- &quot;Sincere Pumpkin Patch&quot; Copyright (C) 2016 The R Foundation for Statistical Computing Platform: x86_64-apple-darwin13.4.0 (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. &gt; という表示が見えるはずだ. 最後の記号 「&gt;」は「プロンプト」と呼ばれる. ここにコマンドを入力せよという意味である. 本書では, コンソールに入力して実行して結果を確認するという文脈であってもプロンプトを表示しない. 各自入力して実行してほしいコマンドは次のようなグレーのボックスで表示する. 10 * 3 ## [1] 30 [1] 30 は実行結果であり, 10 * 3 の結果が 30 であることを意味している. 先頭についている ## は特に意味はない. [1] は今のところ無視してもよい. コマンドの直後に配置された白背景のボックスに直前のコマンドの実行結果を掲載する. プロンプトを省略することで, 複数行にわたるコマンドであってもコピー＆ペーストで実行できるという利点がある. 次のコードをまるごとコピーして, コンソールにペーストし, Enter を押下すればPlotsペインに結果が出力されるはずだ. # 01-cobbdouglas-plot.R A = 1.2 alpha = 0.3 cobbdouglas = function(k) { return(A * k ^ alpha) } k = seq(0, 10, length.out=200) y = cobbdouglas(k) plot(k, y, type=&#39;l&#39;) 図 1.1: ‘01-cobbdouglas-plot.R’ の実行結果 # に続く内容は, プログラマが読むためだけのコメントである. 本書の約束事として, コードチャンクの1行目のコメントには, スクリプトとして保存する場合のファイル名や, 本文中で参照するための短いキャプションを書くことにする. スクリプトファイル スクリプトファイルを保存するディレクトリを作っておこう. Files ペインを探して内容を見ると linear-economic-dynamics.Rproj ファイルを見つけられる思う. そこがプロジェクトディレクトリの最上位階層 (ルートディレクトリ) である. もし当該ファイルが見当たらなければ, ディレクトリ階層を移動して探してほしい. 元いた場所から離れることができたのだから戻ることもできるはずだ. 帰れなくなったら RStudio を終了して, 再び .Rproj をダブルクリックして起動しなおせばよい. プロジェクトの .Rpoj ファイルが見つかったら「New Folder」というボタンを押して, 「R」という名前の新しいディレクトリを作る. スクリプト (script)とは1つ以上のコマンドをまとめたファイルのことである. R はスクリプトファイルを読んで, 上から順番に実行することができる. コンソール上での作業は複数行に渡るコードを入力するには不向きなので, 別途ファイルに保存しておくことで生 RStudio で新しいスクリプトファイルを作るにはいくつかの方法がある. RStudio 左上にあるるボタン (白い四角の上に足し算記号のマーク) から「R Script」を選びクリックする. メニューから「File &gt; New File &gt; R Script」と進む. キーボードショートカット Ctrl+Shift+N / Cmd+Shift+N を押下する 最後のキーボードショートカットを覚えるのが一番よいだろう. Cmd+Shit+N を押下すると, Untitled1 という名前でソースペインが開く. ここに先程の 01_cobbdouglas_plot.R のコードをコピー＆ペーストしてみよう. Ctrl+S / Cmd+S によって保存しようとすると, 保存場所と名前を決めるように促されるので, 先程作成しておいた R というフォルダに, 01_cobbdouglas_plot.R という名前で配置する. プロジェクトディレクトリは次のような構成になっているはずだ.5 linear-economic-dynamics ├── R │   └── 01_cobbdouglas_plot.R └── linear-economic-dynamics.Rproj 作業ディレクトリ (linear-economic-dynamics) にある, R というサブディレクトリの中にある 01_cobbdouglas_plot.R というスクリプトファイルを実行するには以下のようにする. source(&#39;R/01_cobbdouglas_plot.R&#39;) 作業ディレクトリを起点としたファイルの位置を相対パス (relative path)という. スクリプト内にファイルパスを書く場合は, やむを得ない事情で移動できない場合を除いて必ず相対パスで指定するようにする. さきほどのスクリプトファイルはもっと下位のサブディレクトリに配置することもできる. 例えば, 章ごと節ごとにディレクトリを作って source(&#39;R/part1/chapter03/section04/subsection01/01.R&#39;) ということも可能ではある. しかし, 階層が深くなりすぎると管理が難しくなるので, できるだけフラットにしておくようにしよう. この本では, R/chapternumber_descriptive_name.R という形式のファイル名をつけ, すべて R ディレクトリの直下に配置する. 1.3.3 パッケージ tidyverse 本書では tidyverse パッケージを利用する. tidyverse はRのデータフレーム操作を円滑にするためのパッケージ群である. 必要なもの以上に関数を読み込むことを望まない場合には, ggplot2, dplyr, tidyr を必要に応じて読み込むとよい. 試しにプロンプトに library(tidyverse) と打ち込んでみよう. エラーが出る場合には次のコマンドでインストールしてから, 再度実行する. install.packages(&quot;tidyverse&quot;) Loading tidyverse: ggplot2 Loading tidyverse: tibble Loading tidyverse: tidyr Loading tidyverse: readr Loading tidyverse: purrr Loading tidyverse: dplyr Conflicts with tidy packages --------------------------- filter(): dplyr, stats lag(): dplyr, stats といったメッセージが出ると思う. tidyverse はパッケージ群なので, 幾つかの個別のパッケージを読み込むのが仕事である. Conflicts が出て心配になるかもしれないが, 特に問題はない. filter(), lag() という関数がデフォルトで読み込まれているにもかかわらず, 同じ名前を持つ dplyr を読み込んだことでfilter(), lag() という関数の実体が変更されてしまった. もし, デフォルトの filter() を使いたければ, stats::filter() と呼び出せばよい. stats:: や dplyr:: といったプレフィックスは, 関数やオブジェクトがどのパッケージで定義されたものかを明示したいときに使う. 本書では, base::data.frame() の代わりに tibble::tibble() を利用する. tibble パッケージは tidyverse に含まれている. 違いを簡単に見ておこう. x = c(1, 2, 3) y = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) z = c(TRUE, TRUE, FALSE) (df = data.frame(x = x, y = y, z = z)) ## x y z ## 1 1 a TRUE ## 2 2 b TRUE ## 3 3 c FALSE (tbl = tibble(x = x, y = y, z = z)) ## # A tibble: 3 × 3 ## x y z ## &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 a TRUE ## 2 2 b TRUE ## 3 3 c FALSE base のデータフレームと比べて, tibble は次の点で扱いやすい. データのサイズを表示してくれる コラムの型情報を表示する (&lt;dbl&gt;, &lt;chr&gt;, &lt;lgl&gt;) 文字列をファクター型にしない ファクター型は, 文字列を内部的に整数値として保存している. これを文字列と思って扱うと問題が起こる. 例えば, &quot;a&quot; &lt; &quot;b&quot; ## [1] TRUE と同じ振る舞いを期待して, 次のような評価をすると問題が起こる: df$y[1] &lt; df$y[2] ## Warning in Ops.factor(df$y[1], df$y[2]): &#39;&lt;&#39; not meaningful for factors ## [1] NA QZ 同様に QZ パッケージもインストールしておこう. 後々利用することになる. install.packages(&quot;qz&quot;) devtools パッケージ開発環境. devtools::github_install() を使って, github レポジトリからパッケージをインストールできるようになる. Step 1: コンパイラをインストールする. Windows: Rtools (https://cran.r-project.org/bin/windows/Rtools/) をインストール Mac: Xcode をインストール Step 2: CRAN からインストール. install.packages(&quot;devtools&quot;) 参考文献 "],
["complexnumbers.html", "第2章 複素数 2.1 はじめに 2.2 複素数 2.3 複素平面（imaginary plane） 2.4 R コード 2.5 極形式 2.6 共役複素数 2.7 補遺：ラムゼーモデル", " 第2章 複素数 2.1 はじめに マクロ経済学の導入的なトピックとして1セクターの最適成長理論を学び，その後，多セクターモデルを学ばないというケースもあるかもしれない。1セクターモデルの典型的な成長経路は単調であり，補遺で詳しく説明するように，このようなケースで複素数を考える必要はない。しかし，応用上用いられるモデルの多くは複数のセクターと多数の内生変数によって構成されるため，1セクターモデルのように単純な成長経路を描かない可能性がある。例えば，ある1点の周りを回転しながらその点に接近するような経路を描くような動学経路を表現するには，実数を考えるだけでは難しい。経済モデルの動学を理解するには複素数の取扱いが必須なのである6。 この節は，経済学の学習の中で複素数に出会ったことのない人を対象とした入門的なトピックを扱っている。上記のような話を具体的なモデルの中で説明できる読者は読み飛ばしても構わない。あるいは，マクロ経済学が未修であって行列の標準化の理論に明るい読者は補遺まで読み飛ばしてもよい。 2.2 複素数 実数 (real number) の集合を \\(\\mathbb R\\) と書く。\\(\\mathbb R\\) に含まれない「数」を1つ追加し，四則演算を自由にできるようにしたものが複素数 (complex number) の集合 \\(\\mathbb C\\) になる。 追加する数は虚数単位 (imaginary unit)と呼ばれる。これは \\[ i^2 + 1 = 0 \\] を成り立たせる \\(i\\) のことである。実際にはそのような \\(i\\) は複数ある (かもしれない) ので，そのうちの1つに \\(i\\) という名前をつける。実数の範囲にはこのような数は存在しないから，\\(i\\) の追加によって \\(\\mathbb R\\) より大きい集合を考えることになる.7 定義 2.1 複素数 (complex number) とは，実数 \\(a\\)，\\(b\\) を用いて \\[ a + bi \\] と書ける数のことをいう。\\(a\\) を実部 (real part)，\\(b\\) を虚部 (imaginary part) という。 いつも \\(a + bi\\) のように書くと読みにくいので，\\(z \\in \\mathbb C\\) に対して, \\[ \\mathrm{Re}~z = a，\\qquad \\mathrm{Im}~z = b \\] のような書き方をする. 複素数同士の四則演算を次のように定義する. 定義 2.2 任意の \\(a_1，a_2，b_1，b_2 \\in \\mathbb R\\) に対して, \\[ \\begin{aligned} (a_1 + b_1 i) + (a_2 + b_2 i) &amp;= (a_1 + a_2) + (b_1 + b_2) i \\\\ (a_1 + b_1 i) - (a_2 + b_2 i) &amp;= (a_1 - a_2) + (b_1 - b_2) i \\\\ (a_1 + b_1 i) (a_2 + b_2 i) &amp;= (a_1 a_2 - b_1 b_2) + (a_1 b_2 + a_2 b_1 ) i. \\end{aligned} \\] \\(a_2 \\neq 0\\) または \\(b_2 \\neq 0\\) であれば， \\[ \\begin{aligned} \\frac{a_1 + b_1 i}{a_2 + b_2 i} = \\left( \\frac{a_1 a_2 + b_1 b_2}{a_2^2 + b_2^2} \\right) + \\left( \\frac{- a_1 b_2 + a_2 b_1}{a_2^2 + b_2^2} \\right) i. \\end{aligned} \\] 2.3 複素平面（imaginary plane） 1つの複素数は \\((a, b)\\) という実数のペアと同一視できるので，平面上の1点として複素数を表現できる。 図2.1 参照。 図 2.1: 複素平面 複素平面は動学の分析に重要な役割を果たすので自ら図を描いて手になじませておくとよい。 2.4 R コード R では複素数を簡単に使うことができる。例えば次のように書くと，z という名前の変数に \\(5 + i\\) という複素数を代入するという意味になる。コンソールで実行してみてほしい. z = 5 + 1i z ## [1] 5+1i 上のコードを次のように書き換えると正しく動くだろうか？何が起こるかを予想する。その後，Rコンソールで実行して予想した結果と比べる. 1 と i の間にはスペースを入れる. 1 を省略して 5 + i と書く. 実部 複素数を代入した変数をもっていれば，関数 Re() によってその実部を取得できる。 Re(z) ## [1] 5 虚部 Im() によって虚部を取得できる. Im(z) ## [1] 1 四則演算 四則演算も通常の数と同じようにできる。 加算 w = 4 - 3i z + w ## [1] 9-2i 減算 z - w ## [1] 1+4i 乗算 z * w ## [1] 23-11i 除算 z / w ## [1] 0.68+0.76i 実数との演算 実数と複素数の演算も自然に行うことができる。結果は常に複素数になる。 10 + z ## [1] 15+1i 注意 R はゼロで割ってもエラーにならない。 z / 0 ## [1] Inf+Infi z / (0 + 0i) ## [1] Inf+Infi 次の結果は複素数になるが z * 0 ## [1] 0+0i 次の結果は真値を返す。 z * 0 == 0 ## [1] TRUE 複素平面上の図示 ggplot2 による作図の基本 base R の plot() 関数は複素数に対応しているが，残念ながら ggplot2 はそのようにはできていない。とは言え ggplot2 の方が強力なので，ggplot2 のイディオムを習得してほしい。 まず実部と虚部を分けてデータフレームに保存しておく。base R の data.frame() ではなく tidyverse パッケージ (tibble パッケージ) の tibble() を用いる。本書では tibble データフレーム（tbl_df）もデータフレームと呼ぶ。 points = tibble(z = c(z, w, z / w)) %&gt;% mutate(re = Re(z), im = Im(z)) points ## # A tibble: 3 × 3 ## z re im ## &lt;cplx&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.00+1.00i 5.00 1.00 ## 2 4.00-3.00i 4.00 -3.00 ## 3 0.68+0.76i 0.68 0.76 今作ったデータフレームの re 列を横軸に，im 列を縦軸にプロットすればよい。 ggplot(points) + geom_point(aes(x=re, y=im, color=factor(z))) + coord_fixed() + xlim(-5, 5) + ylim(-5, 5) # この行は装飾 べき乗 上の方法をもう少し進めてみよう。同じ複素数を繰り返し掛けるとどうなるだろうか。 \\[ z_p = 0.5 + 0.5i \\] として，\\(z_p^n\\) を計算する。ただし，\\(z_p^n\\) は \\(z_p\\) のべき乗で，実数と同様 \\(z_p^0 = 1\\)，\\(z_p^n = z_p z_p^{n-1}\\)，\\(n &gt; 1\\) と定義する8。 zp = 0.5 + 0.5i zn = tibble(re = Re(1), im = Im(1), n = 0) for (i in 1:10) { zn = zn %&gt;% add_row(re = Re(zp ^ i), im = Im(zp ^ i), n = i) } ggplot(zn) + geom_point(aes(x=re, y=im, color=factor(n))) + coord_fixed() + xlim(-1.02, 1.02) + ylim(-1.02, 1.02) \\(1\\) に \\(0.5 + 0.5i\\) を繰り返し掛けると次第に原点に近づいていくことが分かる。これは，実部・虚部ともに \\(0.5\\) という比較的小さな数字だから成り立ちそうな気がする。実数の場合，\\(\\lim_{n\\to \\infty} a^n = 0\\) となるのは，\\(-1 &lt; a &lt; 1\\) の場合ということを思いだしてほしい。複素数の場合には，実部・虚部のそれぞれが\\(1\\) より小さい絶対値を持てば原点に収束するだろうか？ 例えば次の例を考えてみよう。 \\[ z_q = 0.9 + 0.9i \\] はたして \\(z_q^n\\) は原点に収束するだろうか？ zq = 0.9 + 0.9i zm = tibble(re = Re(1), im = Im(1), n = 0) for (i in 1:10) { zm = zm %&gt;% add_row(re = Re(zq ^ i), im = Im(zq ^ i), n = i) } ggplot(zm) + geom_point(aes(x=re, y=im, color=factor(n))) + coord_fixed() + xlim(-12, 12) + ylim(-12, 12) 上の図を見る限り，回転しながらどんどん原点から離れていっているようだ。原点への収束，原点からの乖離はどのような条件で特徴付けられるだろうか。 2.5 極形式 複素数のべき乗を計算するということは \\(1\\) に同じ複素数を繰り返し掛けることに外ならない。その結果として，上で描いた2つの図のように回転と拡大・縮小という現象を確認することができた。 複素数 \\(z = a + bi\\) を平面上の点 \\((a, b)\\) とみなせるというのが，複素平面を描いた際に念頭に置いていた事実であった。さらに平面上の点 \\((a, b)\\) は原点からの距離と 矢線ベクトル \\((1, 0)\\) を基準とした回転角で表せるということを思い出してほしい。つまり，ある \\(0 \\le \\theta &lt; 360^\\circ\\) が存在して次の等式が成立する. \\[ \\begin{aligned} a = \\sqrt{a^2 + b^2} \\cos \\theta\\\\ b = \\sqrt{a^2 + b^2} \\sin \\theta\\\\ \\end{aligned} \\] \\(r = \\sqrt{a^2 + b^2}\\ge 0\\) を \\(z = a + bi\\) の絶対値 (absolute value)という。\\(z\\) の絶対値を \\(|z|\\) で表す。\\(\\theta\\) を偏角 (argument) という (\\(\\mathrm{arg}(z)\\) で表すこともある)。すべての複素数が \\[ z = r(\\cos\\theta + i\\sin\\theta) \\] という表現を持つ。この表現を複素数の極形式 (polar form)という。図2.2 参照。 図 2.2: 極形式 絶対値が\\(1\\) で偏角の異なる2つの複素数 \\(\\cos\\theta_1 + i\\sin\\theta_1\\) と \\(\\cos\\theta_2 + i\\sin\\theta_2\\) を掛け合わせると \\begin{align} &amp;(\\cos\\theta_1 + i\\sin\\theta_1)(\\cos\\theta_2 + i\\sin\\theta_2) \\notag \\\\ &amp;\\qquad= (\\cos\\theta_1 \\cos\\theta_2 - \\sin\\theta_1\\sin\\theta_2) + i(\\sin\\theta_1\\cos\\theta_2 + \\cos\\theta_1\\sin\\theta_2) \\notag \\\\ &amp;\\qquad= \\cos(\\theta_1 + \\theta_2) + i\\sin(\\theta_1 + \\theta_2) (\\#eq:polar) \\end{align} を得る.9 絶対値が\\(1\\)でない場合にも，\\(r_1, r_2 &gt; 0\\) として, \\[ \\begin{aligned} r_1(\\cos\\theta_1 + i\\sin\\theta_1)\\cdot r_2(\\cos\\theta_2 + i\\sin\\theta_2) = r_1 r_2 \\left[ \\cos(\\theta_1 + \\theta_2) + i\\sin(\\theta_1 + \\theta_2) \\right] \\end{aligned} \\] つまり，複素数 \\(r_2(\\cos\\theta_2 + i\\sin\\theta_2)\\) を掛けるという操作は，絶対値を \\(r_2\\) 倍に伸縮し，偏角を \\(+\\theta_2\\) だけ回転させる作用がある。 オイラーの公式 式(??) は複素数の積が偏角の和に相当することを述べている。この等式を眺めて指数関数との関連性に気がつく人もいるかもしれない。実際， \\begin{align} e^{i\\theta} = \\cos\\theta + i\\sin\\theta (\\#eq:euler) \\end{align} と定義すれば，指数法則 \\[ e^{i\\theta_1} e^{i\\theta_2} = e^{i(\\theta_1 + \\theta_2)} \\] によって，式(??) を「導出」できる。本来は，\\(e^{i\\theta}\\) が意味するところをきちんと定義して，等式 (??) を証明する必要があるだろうが，ここでは記号として「オイラーの公式」を紹介した。関心のある読者は適当な複素関数論の教科書を読めばよい。 すべての複素数が \\begin{equation} z = re^{i\\theta}, \\quad r \\ge 0,\\ 0^\\circ \\le \\theta &lt; 360^\\circ \\end{equation} という表現を持つということを知っていればよい。なお, この表現は次のようにして, \\(\\theta &lt; 0^\\circ\\), \\(\\theta \\ge 360^\\circ\\) に拡張することができる: 任意の \\(\\theta\\) に対して, \\(\\theta = \\theta_0 + n \\times 360^\\circ\\) なる整数 \\(n = 0, \\pm 1, \\pm 2, \\dots\\) がたった1つだけ存在する。\\(e^{i360^\\circ} = 1\\) に注意すれば, \\begin{equation} e^{i\\theta} = e^{i\\theta_0}\\left(e^{i360^\\circ}\\right)^n = e^{i\\theta_0} \\end{equation} を得る。 べき乗 以上の準備の下で, \\[ \\begin{aligned} \\lim_{n\\to\\infty} z_p^n = (0.5 + 0.5i)^n \\to 0, \\quad \\text{and}\\quad \\lim_{n\\to\\infty} z_q^n = (0.9 + 0.9i)^n \\not\\to 0 \\end{aligned} \\] について説明することができる。 極形式による表現 \\[ \\begin{aligned} z_p = r_p e^{i\\theta_p}\\\\ z_q = r_q e^{i\\theta_q} \\end{aligned} \\] によれば, \\[ \\begin{aligned} r_p = \\sqrt{0.5^2 + 0.5^2} \\simeq 0.7071068 &lt; 1\\\\ r_q = \\sqrt{0.9^2 + 0.9^2} \\simeq 1.2727922 &gt; 1. \\end{aligned} \\] したがって, \\[ \\begin{aligned} |z_p^n| &amp;= |r_p^n e^{i n\\theta_p}| = r_p^n \\to 0\\\\ |z_q^n| &amp;= |r_q^n e^{i n\\theta_q}| = r_q^n \\to \\infty \\end{aligned} \\] を得る。この観察をまとめておこう。 \\(|z| &lt; 1\\) ならば \\(\\lim_{n\\to\\infty} |z^n| = 0\\), \\(|z| &gt; 1\\) ならば \\(\\lim_{n\\to\\infty} |z^n| = \\infty\\), \\(|z| = 1\\) ならば 任意の \\(n\\) について \\(|z^n| = 1\\). べき乗の収束性（安定性）は考えている複素数が複素平面上で原点を中心とする単位円（unit circle）の内側（単位円盤 unit disk の上）にあるかどうかで決まる。図2.3において，\\(z_1\\)のべきは発散し，\\(z_2\\)のべきは原点に収束する。 図 2.3: 単位円 2.6 共役複素数 複素数 \\(z = a + bi\\) に対して, \\(\\bar z = a - bi\\) を共役複素数 (complex conjugate)あるいは複素共役という。\\(z\\) は \\(\\bar z\\) の共役複素数であるから, \\begin{equation*} \\bar{\\bar z} = z \\end{equation*} が成り立つ。（@ref(fig:conjugate）） 図 2.4: 共役複素数 共役複素数には次の性質がある。 任意の複素数 \\(z\\) に対して, \\[ z\\bar z = |z|^2 \\] を示せ。 R では, Conj() で複素共役を, abs() で複素数の絶対値を計算できる. z ## [1] 5+1i Conj(z) ## [1] 5-1i abs(z) ## [1] 5.09902 先程の練習問題の性質は z * Conj(z) と abs(z) ^ 2 の差が十分ゼロに近いことで確認できる。 z * Conj(z) - abs(z) ^ 2 ## [1] 3.552714e-15+0i e-15 というのは，10^{-15} を意味しているので，大変小さい数字であることが分かるだろう。あるいは，次の様にすればよい. all.equal(z * Conj(z), abs(z)^ 2 + 0i) ## [1] TRUE 計算機上の小数 (浮動小数点数) は実数を有限近似したものに過ぎないので等号で評価することはできない。有限の長さを持つように見えるありきたりな有理数でさえ，等号による評価はあてにならない。例えば次のような例がある. sum = 0 for (i in 1:10) { sum = sum + 0.1 } sum == 1 ## [1] FALSE 0.1 を 10回足しても 1 にはならない。小数の比較に == を用いてはいけない。 多項式方程式の解 後ほど明らかになるように，線形システムは固有多項式と呼ばれる実係数多項式を「因数分解」する問題を通じて分析される。あるいは， 本質的には同じことだが，実係数多項式方程式の解（根 root）を調べる10。いずれにせよ実係数多項式方程式が重要な役割を果たす。 多項式方程式は次のような性質を持つ。 定理 2.1 (代数学の基本定理) \\(a_n, \\dots, a_0 \\in \\mathbb C\\) とする。\\(z\\) の多項式 \\[ p(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0 \\] は，複素数の範囲で（重根を重複度の回数数えれば）ちょうど \\(n\\) 個の根（root）をもつ。 適当な代数学・複素関数論の本を参照のこと。複素係数の多項式方程式の解は必ず複素数に含まれる。 この性質をもって \\(\\mathbb C\\) は代数的閉体であると言われる11。 実数係数多項式方程式が複素根をもつ時，その共役複素数もまた根である。 定理 2.2 \\(a_n, \\dots, a_0 \\in \\mathbb R\\) とする。\\(z\\) の多項式 \\[ p(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0 \\] が\\(z_0 \\in \\mathbb C\\) で \\(p(z_0) = 0\\) を満たせば，\\(p(\\bar z_0) = 0\\) が成り立つ。 証明. 任意の \\(a \\in \\mathbb R\\) に対して\\(\\bar a = a\\) であることと，\\(\\overline{z^n} = (\\bar z)^n\\) に注意する。\\(\\overline{p(z)} = p(\\bar z)\\) が成り立つので，\\(p(z) = 0\\) ならば \\(p(\\bar z) = 0\\) が言える。 2.7 補遺：ラムゼーモデル 章の冒頭に1セクターモデルの話を書いたので，マクロ経済学を未修の読者のために補足をしておこう。 大学院初級のマクロ経済学を履修したことがあって，「複素数は出てこなかったし，これからも出会うことはない」と考えていた読者にもぜひ読んでほしい。 多くのマクロ経済モデルは最適成長モデル（optimal growth model）あるいはラムゼーモデル（Ramsey model）と呼ばれる基本モデルをベースに組み立てられている。 最適成長モデルは次のような無限ホライズンの最大化問題として記述される。 \\[ \\begin{aligned} &amp; \\max_k \\sum_{t = 0}^\\infty \\beta^t u(k_t, k_{t + 1}) \\\\ &amp; \\begin{array}{ll} \\text{subject to} &amp; k_{t + 1} \\in \\Gamma(k_t), \\ t = 0, 1, \\dots \\\\ &amp; k_0 &gt; 0: \\text{given} \\end{array} \\end{aligned} \\] 登場する記号について少しずつ説明していこう。 標準的な成長理論の文脈では \\(k_t\\) は \\(t\\)-期の期初の資本（capital at the beginning of period \\(t\\)）, \\(k_{t + 1}\\) は\\(t\\)-期の期末の 資本（capital at the end of period \\(t + 1\\)），これはすなわち\\((t+1)\\)-期の期初資本，と解釈される。 次期に残すことのできる資本 \\(k_{t+1}\\) は経済で利用可能な生産技術 \\(\\Gamma\\) と今期利用可能な資本 \\(k_t\\) によって定まる。これが制約式\\(k_{t + 1} \\in \\Gamma(k_t)\\) の意味するところである。 標準的なマクロモデルでは，\\(\\Gamma\\) は生産技術を表す関数 (生産関数, production function) \\(f\\) を使って \\[ \\Gamma(x) = [0, f(x)] \\] と表される対応（correspondence）と考えることが多い12。 すなわち，\\(0 \\le k_{t + 1} \\le f(k_t)\\) が成り立たなければならないというのが制約条件の要請である。 生産関数 \\(f\\) は \\(f(0) = 0\\)，\\(f&#39;(x) &gt; 0\\)，\\(f&#39;&#39;(x) &lt; 0\\) などの性質を持つものと仮定される。1つ目の性質は， 生産には要素投入（factor input）が必須であることを表している。2つ目は，投入量が多ければ産出も多いことを意味している。 最後の性質は，限界生産性逓減（diminishing marginal productivity）と呼ばれる性質で， 要素投入１単位当たりの成果物が徐々に小さくなっていくことを意味している。 1日100枚皿を作れる職人を100人雇っても1日に10000枚の皿を作れるようにはならない。 コミュニケーションや利用できる土地などの制約によってどうしてもボトルネックが生じる。 1セクターモデルというのは，数学的には，\\(k_t\\)，\\(t = 0, 1, \\dots\\)， が（非負の）実数であるようなモデルのことである。経済学の言葉を使うと，財は1種類のみ 存在している。資本を \\(k_t\\) だけ持っている経済において，\\(f(k_t)\\) の産出が得られる。 次期に残す資本として \\(k_{t + 1}\\) を確保しようとする。 簡単ではあるが，これで投資（investment）とか貯蓄（saving） と呼ばれる経済活動の一番簡単な定式化になっている。 さて，残った \\(f(k_t) - k_{t+1}\\) はどこに行っただろう。実は，1セクターモデルでは 経済主体がこれを食べてしまうと考える。機械や建物（生産要素）としても， さらには食事（最終財）にも使える財を1種類だけ生産し，最適な貯蓄と消費のバランスを 見つけるのが 1 セクターモデルの目標である。いかにも奇妙ではあるが， 長期的な経済成長に関する比較的良好な見通しを得ることができる。 \\(t\\)-期の消費（consumptions）を \\(c_t = f(k_t) - k_{t + 1}\\) と表そう。さらに，経済主体は消費のみから効用を 得ると仮定する。すなわち，資本が沢山あったとしてもそれ自体は効用を生まない。 もちろん，これも単純化のための仮定である。各期の消費から得られる効用の水準を効用関数（utility function），\\(U(c_t\\)， で表せるとして， \\[ U(c_t) = U(f(k_t) - k_{t + 1}) = u(k_t, k_{t + 1}) \\] とできる。右辺のように書き直したものが \\(u\\) の正体である。\\(u\\) を既約型効用関数（reduced-form utility function）という13。 消費量は多ければ多いほうが幸せなので，\\(U\\) は単調増加である。ただし，1単位の 追加的な消費量に対して \\(U(c)\\) が増える程度，\\(U&#39;(c)\\)，は \\(c\\) の大きさに依存して変化するする。 典型的には \\(c\\) が大きければ大きいほど \\(U(c)\\) は増えにくくなるだろうから，\\(U&#39;&#39;(c) &lt; 0\\) と仮定するのが標準的である。これを限界効用逓減（diminishing marginal utility）という。 さて，我々が最大化したい対象は \\(U(c_t)\\) ではない。これを重み付き平均を取ったものである。 \\(0&lt; \\beta &lt; 1\\) を割引因子（discount factor）という14。 重み \\(\\beta^t\\) は \\(t\\) が大きくなるに連れてゼロに近づいていく。すなわち，将来の消費は 現在の消費と比べるとウェイトが低く重要ではないということを表現している。\\(\\beta\\) が1に近いほど， 減少のスピードがゆっくりになるので，将来を比較的大切に考える経済主体のモデルとなる。 最適化のための必要条件は \\[ u_2(k_{t-1}, k_t) + \\beta u_1 (k_t, k_{t+1}) = 0 \\] で与えられる。ただし，\\(u_1 = \\partial u/\\partial k_t\\), \\(u_2 = \\partial u/\\partial k_{t+1}\\)。 この動学方程式を不動点（steady state）\\(k^*\\) のまわりで線形化（linearize）すると，線形化方程式 \\[ u_{21}^* \\cdot (k_{t-1} - k^*) + (u_{22}^* + \\beta u_{11}^*) \\cdot (k_t - k^*) + \\beta u_{12}^* \\cdot (k_{t+1} - k^*) = 0 \\] が得られる。ここでは\\(u_{12}^* = \\frac{\\partial^2 u}{\\partial k_t \\partial k_{t+1}}(k^*, k^*)\\) などと置いた。 この線形化方程式は \\((k_t, k_{t+1}) = (k^*, k^*)\\) の近傍の動学を近似する動学方程式である。 \\(\\hat k_t := k_t - k^*\\) と置き，\\(u_{12}^* \\neq 0\\) を仮定すると15， \\[ \\hat k_{t+1} + \\left(\\frac{u_{22}^* + \\beta u_{11}^*}{\\beta u_{12}^*} \\right) \\hat k_t + \\beta^{-1} \\hat k_{t-1} = 0 \\] このような漸化式（recurrence relation）あるいは差分方程式（difference equation）を解くには， 特性方程式（characteristic equation） \\begin{equation} \\lambda^2 + \\left(\\frac{u_{22}^* + \\beta u_{11}^*}{\\beta u_{12}^*} \\right) \\lambda + \\beta^{-1} = 0 \\tag{2.1} \\end{equation} を解けばよいのであった。 次の定理は Levhari and Liviatan (1972) と Santos (1991) による結果の1セクター版である。 定理 2.3 方程式 (2.1) の根はともに実数である。 証明. 2次方程式の根は2つしかないから，\\(\\lambda_1\\), \\(\\lambda_2\\) は互いに共役（\\(\\bar \\lambda_1 = \\lambda_2\\)）であるか， いずれも実数（\\(\\lambda_1, \\lambda_2 \\in \\mathbb R\\)）でなければならない。しかし，簡単に確かめられるように方程式 (2.1) の根 \\(\\lambda \\neq 0\\) が1つ見つかったとき，\\(\\beta^{-1} \\lambda^{-1}\\) もまた方程式 (2.1) の根である。 仮に \\(\\lambda\\) が複素根であるとすれば，\\(\\bar \\lambda\\) も根であるから，\\(\\lambda = \\beta^{-1} \\lambda^{-1}\\) が成り立たなければ根が4つになってしまうので不合理である。\\(\\lambda = \\beta^{-1} \\lambda^{-1}\\) として計算を進めると方程式 (2.1) は次の方程式と同値であることが分かる（確認せよ）。 \\[ \\left(\\lambda + \\frac{u_{12}^*}{u_{22}^*} \\right) \\overline{\\left(\\lambda + \\frac{u_{12}^*}{u_{22}^*} \\right)} + \\frac{u_{11}^* u_{22}^* - (u_{12}^*)^2}{(u_{22})^2} = 0. \\] 第1項は複素数の絶対値と同じ形式であるから正であり，第2項は，\\(U&#39;&gt;0\\), \\(U&#39;&#39;&gt;0\\) および \\(f&#39;&#39;&lt;0\\)の仮定により正である。 したがって，この方程式は成立しえない。つまり，\\(\\lambda\\) は実数でなければならない。 以上が 1セクターのラムゼーモデルで複素数に出会わない理由である。 参考文献 "],
["matrix.html", "第3章 行列論の基礎 3.1 行列の形 3.2 行列の演算 3.3 線形方程式", " 第3章 行列論の基礎 本章と次章では学部初年次の入門的な線形代数学で学ぶ重要項目のうち関連するものを復習する。経済動学の学習に最低限必要な項目を取り上げているが，十分に網羅的になっている訳ではないので， 線形代数学の成書を1つ手元に置いておくのがよいと思う. 本章では行列の形態にまつわる名称や基本演算および初等変形を定義する。次章以降で明らかになるように，線形動的システムの係数行列に対して初等変形を施すことで， 同等な解を持ち分析が容易な動的システムを導出できる。安定性分析の基礎となる重要な 3.1 行列の形 システムの振る舞いをよりよく理解するためには抽象的な線形空間論まで踏み込む必要があるが，それは次回以降に譲って，ここでは表形式に数を並べたものとして行列 (matrix) を捉えよう。従って，行列とは次のような対象である。 \\[ A = \\begin{bmatrix} a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,n-1} &amp; a_{1,n} \\\\ a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,n-1} &amp; a_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ a_{m-1,1} &amp; a_{m-1,2} &amp; \\cdots &amp; a_{m-1,n-1} &amp; a_{m-1,n}\\\\ a_{m,1} &amp; a_{m,2} &amp; \\cdots &amp; a_{m-1,n} &amp; a_{m,n} \\end{bmatrix} \\] ただし，\\(a_{i,j}\\in\\mathbb{F}\\)，\\(i=1,\\dots,m\\)，\\(j=1,\\dots,n\\)。\\(\\mathbb{F}\\) は \\(\\mathbb{R}\\) または \\(\\mathbb{C}\\)。数 \\(a_{i,j}\\) を行列の成分または要素 (element，component，entry) と呼ぶ。混乱の恐れがない場合はコンマを外して \\(a_{ij}\\) と書くことが多い。成分を明らかにするための簡略表記として \\(A=[a_{ij}]\\) といった書き方をする場合がある。また，行列 \\(A\\) の \\((i,j)\\) 成分 \\(a_{ij}\\) を\\(A_{ij}\\) のように書くこともある. 各 \\[ \\begin{aligned} &amp;\\begin{bmatrix}a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,n-1} &amp; a_{1,n}\\end{bmatrix}\\\\ &amp;\\begin{bmatrix}a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,n-1} &amp; a_{2,n}\\end{bmatrix}\\\\ &amp;\\hspace{6em}\\vdots\\\\ &amp;\\begin{bmatrix}a_{m,1} &amp; a_{m,2} &amp; \\cdots &amp; a_{m,n-1} &amp; a_{m,n}\\end{bmatrix} \\end{aligned} \\] を行列の行 (row) という。一方，各 \\[ \\begin{bmatrix} a_{1,1}\\\\ a_{2,1}\\\\ \\vdots\\\\ a_{m-1,1}\\\\ a_{m,1} \\end{bmatrix}, \\ \\begin{bmatrix} a_{1,2}\\\\ a_{2,2}\\\\ \\vdots\\\\ a_{m-1,2}\\\\ a_{m,2} \\end{bmatrix}, \\ \\dots,\\ \\begin{bmatrix} a_{1,n}\\\\ a_{2,n}\\\\ \\vdots\\\\ a_{m-1,n}\\\\ a_{m,n} \\end{bmatrix} \\] を行列の列 (column) という。上の行列\\(A\\) は\\(m\\)個の行と\\(n\\)個の列を持つので，\\(m\\times n\\) 行列と呼ばれる。\\(\\mathbb{F}^{m\\times n}\\) を \\(\\mathbb{F}\\) の値を成分にもつ \\(m\\times n\\) 行列の全体の集合と定義する。 行列の形にまつわるいくつかの用語を確認しておこう。 正方行列 (square matrix) \\(m=n\\) のとき，すなわち \\(A\\in\\mathbb{F}^{n\\times n}\\) のとき，\\(A\\) は \\(n\\) 次の正方行列 (square matrix of order \\(n\\)) であるいう。 ゼロ行列 (zero matrix，null matrix) すべての成分がゼロである行列をゼロ行列という。サイズが \\(m\\times n\\) であるゼロ行列を \\(0_{m\\times n}\\) とか \\(O_{m\\times n}\\) と書く。多くの場合にそうであるように，混乱の恐れがない場合には \\(O\\) とか \\(0\\) と書く。 対角成分 (diagonal elements) 正方行列 \\(A\\) の成分 \\(\\{a_{ij}\\ |\\ i,j=1,\\dots,n\\}\\) のうち \\(i=j\\) なる部分 \\(\\{a_{11},\\dots,a_{nn}\\}\\) を対角成分 (diagonal element)という。対角成分の1つ上の成分 \\(\\{a_{12},a_{23},\\dots,a_{n-1,n}\\}\\) を優対角成分 (superdiagonal element)，対角成分の1つ下の成分 \\(\\{a_{21},a_{32},\\dots,a_{n,n-1}\\}\\) を劣対角成分 (subdiagonal element) という。対角成分の和をトレース (trace) といい，\\(\\mathrm{trace}A\\) と書く. 三角行列 (triangular matrix) 正方行列\\(A=[a_{ij}]\\) が \\(i&gt;j\\Rightarrow a_{ij}=0\\) を満たすとき，\\(A\\) を上三角行列 (upper triangular matrix) という。一方，\\(A=[a_{ij}]\\) が \\(i&lt;j\\Rightarrow a_{ij}=0\\) を満たすとき，\\(A\\) は下三角行列 (lower triangular matrix) であるという。上三角行列は対角成分より下にある成分がすべてゼロ，下三角行列は対角成分より上にある成分がすべてゼロである。 対角行列 (diagonal matrix) 対角成分を除いた成分がすべてゼロであるような正方行列を対角行列 (diagonal matrix)という。ときに，\\(\\mathrm{diag}\\{a_{1},\\dots,a_{n}\\}\\) のように書いて対角成分が左上から順に \\(a_{1},\\dots,a_{n}\\) である対角行列を表すことがある。これは Matlab などで利用されている記法で，Python と Octave でも利用できる. 単位行列 (identity matrix) 対角成分がすべて\\(1\\) である対角行列を単位行列という。\\(n\\)次の単位行列を \\(I_{n}\\) と書く。誤解の恐れがない場合は単に \\(I\\) と書く。Python では関数 numpy.eye(n) で \\(n\\) 次単位行列を作る. 転置行列 (transpose matrix) \\(A=[a_{ij}]\\in\\mathbb{F}^{m\\times n}\\) の転置行列 \\(A^{\\top}\\) とは，\\((A^{\\top})_{ij}=a_{ji}\\), \\(i=1,\\dots,m\\)，\\(j=1,\\dots n\\) を満たす\\(m\\times n\\)行列のことをいう。 共役転置行列 (conjugate transpose) \\(A=[a_{ij}]\\in\\mathbb{F}^{m\\times n}\\) の共役転置行列 \\(A^{*}\\) とは，\\((A^{*})_{ij}=\\bar{a}_{ji}\\), \\(i=1,\\dots,m\\)，\\(j=1,\\dots n\\) を満たす\\(m\\times n\\)行列のことである。実行列の共役転置行列は転置行列である. 対称行列 (symmetric matrix) \\(A\\in\\mathbb{R}^{n\\times n}\\) が対称行列 (symmetric matrix)であるとは，\\(A^{\\top}=A\\) が成り立つことをいう. エルミート行列 (Hermitian matrix) \\(A\\in\\mathbb{C}^{n\\times n}\\) がエルミート行列であるとは，\\(A^{*}=A\\) が成り立つことをいう. 列ベクトル・行ベクトル (column vector，row vector) のちに見るように行列の集合には元どうしの加法とスカラー倍が定義され，それらは望ましい性質を満たす。ゼロ元・逆元と呼ばれる特別な元の存在も自明であるので，特定のサイズの行列全体の集合は，(のちに定義する) ベクトル空間の一例となっている。特に \\[ \\mathbb{F}^{n\\times1},\\quad\\mathbb{F}^{1\\times n} \\] は我々が頻繁に用いる有限次元ベクトル空間の表現となっている。通常これらのうちいずれかを \\(\\mathbb{F}^{n}\\) と記す. 一般の \\(A\\in\\mathbb{F}^{n\\times m}\\) を\\(n\\)次元列ベクトル (\\(\\mathbb{F}^{n\\times1})\\) を \\(m\\) 個並べたものと捉えたり，\\(m\\)次元列ベクトル (\\(\\mathbb{F}^{1\\times m})\\) を \\(n\\) 個並べたものと捉えたりすることがある. ブロック行列 (block matrix) 行列をいくつかの部分行列に分解した上で分析する方が都合の良い場合がある。例えば, \\[ A=\\left[ \\begin{array}{ccc|ccc} a_{1,1} &amp; \\cdots &amp; a_{1,n} &amp; a_{1,n+1} &amp; \\cdots &amp; a_{1,n+q}\\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ a_{m,1} &amp; \\cdots &amp; a_{m,n} &amp; a_{m,n+1} &amp; \\cdots &amp; a_{m,n+q}\\\\ \\hline a_{m+1,1} &amp; \\cdots &amp; a_{m+1,n} &amp; a_{m+1,n+1} &amp; \\cdots &amp; a_{m+1,n+q}\\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ a_{m+p,1} &amp; \\cdots &amp; a_{m+p,n} &amp; a_{m+p,n+1} &amp; \\cdots &amp; a_{m+p,n+q} \\end{array} \\right] =: \\left[ \\begin{array}{c|c} A_{11} &amp; A_{12}\\\\ \\hline A_{21} &amp; A_{22} \\end{array} \\right] \\] のように，大きな行列 \\(A\\in\\mathbb{F}^{(m+p)\\times(n+q)}\\) を4つの部分行列 \\(A_{11}\\in\\mathbb{F}^{m\\times n}\\), \\(A_{12}\\in\\mathbb{F}^{m\\times q}\\)，\\(A_{21}\\in\\mathbb{F}^{p\\times n}\\), \\(A_{22}\\in\\mathbb{F}^{p\\times q}\\) に分解するなどである.16 \\(A_{12}=0\\)，\\(A_{21}=0\\) であるとき，ブロック対角行列 (block diagonal matrix)であるといい，\\(A_{21}=0\\) であるときブロック上三角行列 (block upper triangular matrix)であるなどという。 3.2 行列の演算 スカラー倍 \\(A\\in\\mathbb{F}^{m\\times n}\\) に対してスカラー倍 (scalar multiplication) あるいは定数倍と呼ばれる操作が次のように定義される: \\(\\alpha\\in\\mathbb{F}\\) について, \\[ \\alpha A:=\\begin{bmatrix}\\alpha a_{1,1} &amp; \\alpha a_{1,2} &amp; \\cdots &amp; \\alpha a_{1,n-1} &amp; \\alpha a_{1,n}\\\\ \\alpha a_{2,1} &amp; \\alpha a_{2,2} &amp; \\cdots &amp; \\alpha a_{2,n-1} &amp; \\alpha a_{2,n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots\\\\ \\alpha a_{m-1,1} &amp; \\alpha a_{m-1,2} &amp; \\cdots &amp; \\alpha a_{m-1,n-1} &amp; \\alpha a_{m-1,n}\\\\ \\alpha a_{m,1} &amp; \\alpha a_{m,2} &amp; \\cdots &amp; \\alpha a_{m-1,n} &amp; \\alpha a_{m,n} \\end{bmatrix}\\in\\mathbb{F}^{m\\times n}. \\] 和 同数の行と列を持つ2つの行列に対して次のようにして和が定義できる。\\(A=[a_{ij}]\\in\\mathbb{F}^{m\\times n}\\), \\(B=[b_{ij}]\\in\\mathbb{F}^{m\\times n}\\) に対して， \\[ A+B:=[a_{ij}+b_{ij}]\\in\\mathbb{F}^{m\\times n}. \\] すなわち，行列の和は成分ごとに和をとった行列である。定義から自明なことであるが，和は交換法則と結合法則を満たす。すなわち, 任意の \\(A,B,C\\in\\mathbb{F}^{m\\times n}\\) について \\[ \\begin{aligned} A+B &amp; =B+A\\\\ A+(B+C) &amp; =(A+B)+C \\end{aligned} \\] が成り立つ。ゼロ行列 \\(0\\in\\mathbb{F}^{m\\times n}\\) は任意の \\(A\\in\\mathbb{F}^{m\\times n}\\)に対して \\[ A+O_{m\\times n}=A \\] を満たす。 積 行列 \\(A=[a_{ij}]\\in\\mathbb{F}^{m\\times n}\\) と \\(B=[b_{ij}]\\in\\mathbb{F}^{n\\times p}\\) の積 \\(AB\\in\\mathbb{F}^{m\\times p}\\) を次のように定義する. \\[ AB:=\\left[\\sum_{k=1}^{n}a_{ik}b_{kj}\\right]. \\] この定義は線形写像の合成という観点から見ればごく自然なものであることが分かる。解説は別の機会に譲ることにしよう。 正方行列 \\(A,B\\in\\mathbb{F}^{n\\times n}\\) に対して，\\(AB\\) と \\(BA\\) の両方が定義される。しかし，それらは一般には一致しない。例えば， \\[ \\begin{aligned} \\begin{bmatrix} 1 &amp; 1\\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0\\\\ 1 &amp; 1 \\end{bmatrix} &amp; \\neq \\begin{bmatrix} 1 &amp; 0\\\\ 1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1\\\\ 0 &amp; 1 \\end{bmatrix} \\end{aligned} \\] である。\\(AB=BA\\) が成り立つとき，\\(A\\) と \\(B\\) は可換であるという。単位行列とゼロ行列は任意の行列と可換である. 任意の \\(A\\in\\mathbb{F}^{n\\times n}\\) に対して \\[ AI_{n}=I_{n}A=A \\] と \\[ AO_{n\\times n}=O_{n\\times n}A=O_{n\\times n} \\] が成り立つ。 行列の積には次の性質がある。 \\[ \\begin{aligned} (AB)C &amp; =A(BC)\\\\ A(B+C) &amp; =AB+AC\\\\ (A+B)C &amp; =AC+BC. \\end{aligned} \\] スカラー\\(\\alpha\\)に対して， \\[ (\\alpha A)B=A(\\alpha B)=\\alpha(AB). \\] 逆行列 (inverse matrix) 正方行列 \\(A\\in\\mathbb{F}^{n\\times n}\\) に対して， \\[ AB=BA=I_{n} \\] なる \\(B\\in\\mathbb{F}^{n\\times n}\\) が存在するとき \\(A\\) は可逆 (invertible) あるいは正則 (regular) であるという。\\(B\\) を \\(A\\) の逆行列 (inverse matrix) といい \\(A^{-1}\\) と記す。 逆行列は存在すれば一意的に定まることを証明せよ. 逆行列は存在すれば正則であることを証明せよ。 \\(A,B\\in\\mathbb{F}^{n\\times n}\\) がともに正則であるとき，\\(AB\\) は可逆であり，\\((AB)^{-1}=B^{-1}A^{-1}\\) が成り立つことを示せ。 直交行列 (diagonal matrix) \\(A\\in\\mathbb{R}^{n\\times n}\\) が直交行列であるとは，\\(A^{\\top}=A^{-1}\\) が成り立つことをいう。 ユニタリ行列 (unitary matrix) \\(A\\in\\mathbb{C}^{n\\times n}\\) がユニタリ行列であるとは，\\(A^{*}=A^{-1}\\) が成り立つことをいう。 3.3 線形方程式 行列とベクトルの組 \\[ \\begin{aligned} A &amp; =[a_{ij}]\\in\\mathbb{F}^{m\\times n},\\\\ b &amp; =[b_{j}]\\in\\mathbb{F}^{m\\times1} \\end{aligned} \\] に対して， \\[ Ax=b \\] を満たす \\(x\\in\\mathbb{F}^{n\\times1}\\) を求める問題を線形方程式 (linear equation)という。\\(Ax\\) は行列\\(A\\)と列ベクトル \\(x\\) の積である。これは次の連立1次方程式の行列表現に外ならない。 \\[ \\begin{cases} a_{11}x_{1}+\\cdots+a_{1n}x_{n}=b_{1}\\\\ \\qquad\\vdots\\\\ a_{m1}x_{1}+\\cdots+a_{mn}x_{n}=b_{m} \\end{cases} \\] 3.3.1 線形連立方程式の変形 要点を理解するために簡単な例を用いよう。連立方程式 \\begin{equation} \\begin{cases} x_{1}+x_{2}=1\\\\ x_{1}-x_{2}=2 \\end{cases} (\\#eq:lineq001) \\end{equation} を行列の形式で表現すると \\begin{equation} \\begin{bmatrix} 1 &amp; 1\\\\ 1 &amp; -1 \\end{bmatrix} \\begin{bmatrix} x_{1}\\\\x_{2} \\end{bmatrix} = \\begin{bmatrix} 1\\\\2 \\end{bmatrix} (\\#eq:lineq002) \\end{equation} と表すことができる。式(??)と全く同じ連立方程式で，順序だけを入れ替えたもの \\begin{equation} \\begin{cases} x_{1}-x_{2}=2\\\\ x_{1}+x_{2}=1 \\end{cases} (\\#eq:lineq003) \\end{equation} を行列表示すると， \\begin{equation} \\begin{bmatrix}1 &amp; -1\\\\ 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix}x_{1}\\\\ x_{2} \\end{bmatrix}=\\begin{bmatrix}2\\\\ 1 \\end{bmatrix} (\\#eq:lineq004) \\end{equation} である。式(??)と式(??)は，全く同じ \\((x_{1},x_{2})\\) が解であるという意味で同値な方程式であるが，係数行列 \\(A\\) と定数項 \\(b\\) が異なっている。この他にも，式(??)の第1式を定数倍した \\begin{equation} \\begin{cases} 2x_{1}-2x_{2}=4\\\\ x_{1}+x_{2}=1 \\end{cases} (\\#eq:lineq005) \\end{equation} や，式(??) の第1式を第2式に足すことで得られる \\begin{equation} \\begin{cases} x_{1}-x_{2}=2\\\\ x_{1}+x_{2}+(x_{1}-x_{2})=1+2 \\end{cases} (\\#eq:lineq006) \\end{equation} も同じ解をもつはずである。各自，式(??)，式(??) の行列表現を確認してほしい。 あるいは次の方程式 \\[ \\begin{cases} x_{2}+x_{1}=1\\\\ -x_{2}+x_{1}=2 \\end{cases} \\] も全く同じ方程式を変形したものなので，その行列表示 \\begin{equation} \\begin{bmatrix}1 &amp; 1\\\\ -1 &amp; 1 \\end{bmatrix}\\begin{bmatrix}x_{2}\\\\ x_{1} \\end{bmatrix}=\\begin{bmatrix}1\\\\ 2 \\end{bmatrix}(\\#eq:lineq007) \\end{equation} も，\\(x_{1},x_{2}\\) の順序は入れ替わるが同じ解を導く。従って，\\((x_{1},x_{2})\\) でなく \\((x_{2},x_{1})\\) の順で解を得たことさえ了解していれば，式(??)と式(??) は本質的に同じ線形方程式である. 見かけ上異なる複数の行列が連立方程式の解という観点から見れば全て同じものになるという事実は応用上大変重要である。連立方程式や動学方程式を分析する上では, もっとも有利な形式に変形してから分析すれば十分なのである。特に，あらかじめ都合のよい形式に変形されているものとして理論分析を行うこともあるので, 応用者は自らそのような形式に変形し，さらに復元できなければいけない。 連立方程式の求解に関していえば，同値な変形を繰り返して \\[ \\begin{cases} x_{1}=*\\\\ x_{2}=* \\end{cases} \\] 形式を導けばよい。行列表示すると \\[ \\begin{bmatrix} 1 &amp; 0\\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} x_{1}\\\\ x_{2} \\end{bmatrix}=\\begin{bmatrix}*\\\\ * \\end{bmatrix} \\] を導けばよい。 3.3.2 行基本変形 連立方程式の変形を行列の言葉で表現してみよう。 行の交換 行列の行に対するもっとも基本的な操作は行の交換であろう。連立方程式は順序付けされてない方程式の組であり，これに無理やり順序付けたものが先ほどの行列表示に他ならないので, 行順序の変更に対して解は不変である。 \\(2\\times2\\) 行列の行順序の変更は行列 \\(\\left[\\begin{smallmatrix}0 &amp; 1\\\\ 1 &amp; 0 \\end{smallmatrix}\\right]\\)を左から掛ける操作に対応する。 \\[ \\begin{aligned} \\begin{bmatrix}0 &amp; 1\\\\ 1 &amp; 0 \\end{bmatrix}\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; -1 \\end{bmatrix}\\begin{bmatrix}x_{1}\\\\ x_{2} \\end{bmatrix} &amp; =\\begin{bmatrix}1 &amp; -1\\\\ 1 &amp; 1 \\end{bmatrix}\\begin{bmatrix}x_{1}\\\\ x_{2} \\end{bmatrix}\\\\ \\begin{bmatrix}0 &amp; 1\\\\ 1 &amp; 0 \\end{bmatrix}\\begin{bmatrix}1\\\\ 2 \\end{bmatrix} &amp; =\\begin{bmatrix}2\\\\ 1 \\end{bmatrix}. \\end{aligned} \\] 次の関係が成り立つことに注目してほしい. \\[ \\begin{bmatrix} 0 &amp; 1\\\\ 1 &amp; 0 \\end{bmatrix}^{-1} = \\begin{bmatrix} 0 &amp; 1\\\\ 1 &amp; 0 \\end{bmatrix}. \\] 従って，式(??) と式(??)は正則行列 \\(\\left[\\begin{smallmatrix}0 &amp; 1\\\\ 1 &amp; 0 \\end{smallmatrix}\\right]\\) を通して互いに変形し合う。 より一般の \\(m\\times n\\) 行列についてどのようになるか考えてみよ。 A\\(\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)行と第\\(j\\)行を入れ替えた結果が行列積 \\(C_{ij}^{m}A\\) で表せるような行列 \\(C_{ij}^{m}\\in\\mathbb{F}^{m\\times m}\\) が存在する。 \\(C_{ij}^{m}\\) の要素をかきだしなさい。 行全体の非ゼロ定数倍 1つの行にゼロでない定数 \\(u\\) をかける操作も行列積を用いて表現できる。ここでも簡単な場合だけ見ておこう。 \\[ \\begin{bmatrix}1 &amp; 0\\\\ 0 &amp; u \\end{bmatrix}\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; -1 \\end{bmatrix}=\\begin{bmatrix}1 &amp; 1\\\\ u &amp; -u \\end{bmatrix}. \\] 次の関係が成り立つことに注目してほしい. \\[ \\begin{bmatrix}1 &amp; 0\\\\ 0 &amp; u \\end{bmatrix}^{-1}=\\begin{bmatrix}1 &amp; 0\\\\ 0 &amp; 1/u \\end{bmatrix}. \\] \\(A\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)行に一斉に非ゼロ定数 \\(u\\) をかけた結果が行列積 \\(D_{i}^{m}(u)A\\) で表せるような行列 \\(D_{i}^{m}(u)\\in\\mathbb{F}^{m\\times m}\\) が存在する。\\(D_{i}^{m}\\) の要素をかきだしなさい。 行の定数倍を別の行に加える 1つの行に(ゼロであってもよい)定数 \\(a\\) をかける操作も行列積を用いて表現できる。簡単な場合だけ見ておこう。 \\[ \\begin{bmatrix}1 &amp; a\\\\ 0 &amp; 1 \\end{bmatrix}\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; -1 \\end{bmatrix}=\\begin{bmatrix}1+a &amp; 1-a\\\\ 1 &amp; -1 \\end{bmatrix}. \\] 次の関係が成り立つことに注目してほしい. \\[ \\begin{bmatrix}1 &amp; a\\\\ 0 &amp; 1 \\end{bmatrix}^{-1}=\\begin{bmatrix}1 &amp; -a\\\\ 0 &amp; 1 \\end{bmatrix}. \\] 一般の場合は練習問題とする。 \\(A\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)行の \\(a\\)倍を第\\(j\\)行に加えた結果が行列積 \\(E_{ij}^{m}(a)A\\) で表せるような行列 \\(E_{ij}^{m}(a)\\in\\mathbb{F}^{m\\times m}\\) が存在する。\\(E_{ij}^{m}(a)\\) の要素をかきだしなさい。 3.3.3 列基本変形 行の変形と同様に，列の変形も定義できる。実は上で得られた行列を「右から」かける操作が列変形に対応している。各自確認しておいてほしい。 \\(A\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)列と第\\(j\\)列を入れ替えた行列は \\(AC_{ij}^{m}\\) と一致する。 \\(A\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)列に一斉に非ゼロ定数 \\(u\\) をかけた結果は \\(AD_{i}^{m}(u)\\) と一致する。 \\(A\\in\\mathbb{F}^{m\\times n}\\) を任意の行列とする。行列の第\\(i\\)列の \\(a\\)倍を第\\(j\\)列に加えた結果は \\(AE_{ij}^{m}(a)\\) と一致する。 列の変形は式(??)で見た「解の並び替え」を一般化したものである。線形方程式 \\[ Ax=b \\] は \\[ AC_{ij}^{m}\\left(C_{ij}^{m}\\right)^{-1}x=b \\] と同値であるから \\(y=\\left(C_{ij}^{m}\\right)^{-1}x\\) と置き換えれば \\[ AC_{ij}^{m}y=b \\] と同値である。この変換については座標変換と関連付けて今後より詳しく学ぶことになる。 3.3.4 初等変形 行列に行基本変形と列基本変形を繰り返して得られる操作を初等変形という。\\(A\\in\\mathbb{F}^{m\\times n}\\)，\\(i=1,\\dots,n_{r}\\)，\\(j=1,\\dots,n_{c}\\) について \\(P_{i}\\) をいずれかの行基本変形，\\(Q_{j}\\) をいずれかの列基本変形とすると \\[ P=P_{n_{r}}\\cdots P_{1},\\quad Q=Q_{1}\\cdots Q_{n_{c}} \\] を用いて初等変形 (の結果) を \\[ PAQ \\] と表すことができる。 \\(P,Q\\) が正則行列であることを示せ. 命題 3.1 任意の行列 \\(A\\in\\mathbb{F}^{m\\times n}\\) に対して，適当に初等変形 \\(P\\)，\\(Q\\) を選べば \\[ PAQ=\\left[\\begin{array}{c|c} I_{d\\times d} &amp; O_{d\\times(n-d)}\\\\ \\hline O_{(m-d)\\times d} &amp; O_{(m-d)\\times(n-d)} \\end{array}\\right] \\] とできる。ここで，\\(d\\) は\\(P,Q\\)の選び方によらず\\(A\\)のみから決まる定数である。 ランク 上の \\(d\\) を行列 \\(A\\) のランク (rank)といい，\\(\\mathrm{rank}A\\) と書く。 一般に \\(\\mathrm{rank}A\\le\\min\\{m,n\\}\\) である。この不等式が等号で成り立つとき，\\(A\\) はフルランク (full rank) であるという。特に，\\(\\mathrm{rank}A=m\\) のとき行フルランク (full column rank)，\\(\\mathrm{rank}A=n\\) のとき列フルランク (full row rank)という。 命題 3.2 行列 \\(A\\in\\mathbb{F}^{n\\times n}\\) が正則であることと，フルランクであることは同値である。 証明. \\(A\\) がフルランクであると仮定する。すなわち \\[ PAQ=I \\] なる初等変形 \\(P\\)，\\(Q\\) がある。左から \\(P^{-1}\\)，右から \\(Q^{-1}\\) をかけてやれば \\begin{equation} A = P^{-1}Q^{-1} \\tag{3.1} \\end{equation} が得られる。右辺は正則なので逆行列が存在する。すなわち \\(A^{-1}=QP\\). \\(A\\) は正則であるがフルランクでないと仮定する。すなわち，\\(d&lt;n\\) に対して \\[ PAQ=\\left[\\begin{array}{c|c} I_{d\\times d} &amp; O_{d\\times(n-d)}\\\\ \\hline O_{(m-d)\\times d} &amp; O_{(m-d)\\times(n-d)} \\end{array}\\right] \\] となる。逆行列 \\(A^{-1}\\) が存在するので，\\(PAQ\\) に右から \\(Q^{-1}A^{-1}\\) をかければ \\[ PAQ(Q^{-1}A^{-1})=P \\] を得る。\\(PAQ\\) の形状により \\(P\\) の \\((d+1)\\) 行目以下はすべてゼロにならなければならないが，このような行列を基本変形の積として表現することはできない. 従って，この等式は不合理である。よって\\(A\\)はフルランクでなければならない. 式(3.1) を少し変形すると \\[ A=P^{-1}Q^{-1}=\\tilde{P}^{-1} \\] なる行基本変形のみ (あるいは列基本変形のみ) からなる初等変形 \\(\\tilde{P}\\) が存在することが分かる。\\(A^{-1}=\\tilde{P}\\) であるから，\\(A\\) から \\(I\\) に至る行基本変形を \\(I\\) に施せば逆行列を得ることができる. \\(P:=Q\\) という表現は，\\(P\\) を \\(Q\\) で定義するという意味，\\(P =:Q\\) は \\(Q\\) を\\(P\\) で定義するという意味である.↩ "],
["eigen.html", "第4章 固有値 4.1 行列式 4.2 固有値と固有ベクトル 4.3 対角化 4.4 線形動学方程式と固有値 4.5 ラムゼーモデルと固有値", " 第4章 固有値 本章では，行列の固有値に関して復習する。 4.1 行列式 4.1.1 置換 有限個の自然数の集合 \\(\\{1,2,\\dots,n-1,n\\}\\) を並び替える方法には \\(n!\\) 通りの方法がある。この並び替え全体の集合を \\(S_n\\) で表す。例えば \\(\\sigma&#39;=(1,2,\\dots,n-1,n)\\) や \\(\\sigma&#39;&#39;=(n,n-1,\\dots,2,1)\\) などが\\(S_{n}\\) の元である。\\(S_{n}\\) の元を置換 (permutation)と呼ぶ。置換 \\(\\sigma\\in S_{n}\\) を \\(\\{1,2,\\dots,n\\}\\) からそれ自身への全単射と考えて，\\(\\sigma&#39;(1)=1\\)，\\(\\sigma&#39;&#39;(n-1)=2\\) などのように書くこともできる. この記法は置換の合成 (通常，「積」と呼ばれる) の自然な定義を導いてくれる。すなわち \\[ (\\sigma_{1}\\sigma_{2})(i)=\\sigma_{1}(\\sigma_{2}(i)),\\quad i=1,2,\\dots,n. \\] 恒等置換 (identity permutation)とは，\\(\\sigma_{id}(i)=i\\)，\\(i=1,\\dots,n\\) なる置換である。互換 (transposition)とは，2つの文字を入れ替える特別な置換である。すなわち \\(i\\neq j\\) に対して \\[ \\pi_{ij}(i)=j,\\quad\\pi_{ij}(j)=i,\\quad\\pi_{ij}(k)=k,\\quad k\\neq i,j. \\] すべての置換は互換の積として表すことができる。例えば，\\(\\sigma=(2,3,4,1)\\) とすれば \\[ (1,2,3,4)\\xrightarrow{\\pi_{1,2}}(2,1,3,4)\\xrightarrow{\\pi_{1,3}}(2,3,1,4)\\xrightarrow{\\pi_{1,4}}(2,3,4,1) \\] なので，\\(\\sigma=\\pi_{1,4}\\pi_{1,3}\\pi_{1,2}\\) となる。この分解の方法は一意的ではないが，分解を構成する互換の数は奇遇が不変となることが知られている。奇数個の互換の積に分解できる置換を奇置換 (odd permutation), 偶数個の互換の積に分解できる置換を偶置換 (even permutation) と呼ぶ。写像 \\(\\mathrm{sgn}:S_{n}\\to\\{-1,1\\}\\) を次のように定義できる. \\[ \\mathrm{sgn}(\\sigma)=\\begin{cases} -1 &amp; \\mbox{if }\\sigma\\mbox{ is odd}\\\\ +1 &amp; \\mbox{if }\\sigma\\mbox{ is even}. \\end{cases} \\] 4.1.2 行列式の定義 正方行列 \\(A=[a_{ij}]\\in\\mathbb{F}^{n\\times n}\\) に対して，行列式 (determinant) \\(\\det A\\) (\\(|A|\\)とも書く) を次のように定義する。 \\[ \\det A=\\sum_{\\sigma\\in S_{n}}\\mathrm{sgn}(\\sigma)a_{1\\sigma(1)}\\cdots a_{n\\sigma(n)}. \\] 命題 4.1 行列式は次の性質を持つ. \\(\\det A^{\\top}=\\det A\\). \\(\\det C_{ij}A=-\\det A\\) (行の交換で符号が変わる). \\(\\det D_{i}^{n}(a)A=a\\det A\\) (行の\\(a\\)倍で行列式が\\(a\\)倍になる。\\(a=0\\) でも成り立つ)。 \\(\\det\\left(E_{ij}^{n}(a)A\\right)=\\det A\\) (行の\\(a\\)倍を別の行に加えても行列式は変化しない). \\[ \\det\\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n}\\\\ a_{i1}+b_{i1} &amp; \\cdots &amp; a_{in}+b_{in}\\\\ a_{n1} &amp; \\cdots &amp; a_{nn} \\end{bmatrix}=\\det\\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n}\\\\ a_{i1} &amp; \\cdots &amp; a_{in}\\\\ a_{n1} &amp; \\cdots &amp; a_{nn} \\end{bmatrix}+\\det\\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1n}\\\\ b_{i1} &amp; \\cdots &amp; b_{in}\\\\ a_{n1} &amp; \\cdots &amp; a_{nn} \\end{bmatrix}. \\] \\(\\det I=1\\). \\(\\det AB=\\det A\\det B\\). 命題 4.1 を証明せよ. \\(A \\in \\mathbb{F}^{n \\times n}\\) が正則であるための必要十分条件は \\(\\det A \\neq 0\\)。 証明. \\(A\\) が正則であるとしよう。このとき，命題 4.1 性質6，7 より， \\(1 = \\det I = \\det A \\det A^{-1}\\) が成り立つから \\(\\det A = 0\\) にはなりえない。 次に，\\(\\det A \\neq 0\\) が成り立つとして，\\(A\\) の正則性を導こう。対偶を示す17。 \\(A\\)が正則でければ \\(A\\)はフルランクでない（命題3.2）。 このとき正則行列 \\(P, Q\\) が存在して， \\[ PAQ=\\left[ \\begin{array}{c|c} I_{d\\times d} &amp; O_{d\\times(n-d)}\\\\ \\hline O_{(m-d)\\times d} &amp; O_{(m-d)\\times(n-d)} \\end{array} \\right] \\] とできる。右辺の行列式は定義によりゼロである。 命題 4.1 性質7 により，\\(\\det P \\det A \\det Q = 0\\)。 正則行列 \\(P, Q\\) に対しては \\(\\det P \\neq 0 \\neq \\det Q\\) が成り立つことが分かっているから， \\(\\det A = 0\\) が成り立たなければならない。 4.1.3 行列式の意味 2次正方行列 \\[ A = \\begin{bmatrix} a &amp; b \\\\ c &amp; d \\end{bmatrix} \\] の行列式は定義に従って容易に計算することができる。 \\[ \\det A = ad - bc \\] この量は，行列\\(A\\)の列を成す2つのベクトル \\[ A_1 = \\begin{bmatrix} a \\\\ c \\end{bmatrix}, \\quad A_2 = \\begin{bmatrix} b \\\\ d \\end{bmatrix} \\] が作る平行四辺形 (parallelogram) の（符号付き）面積と一致する（図4.1の色付き部分）。 図 4.1: 列ベクトルが成す平行四辺形 一般の次数でも同様の考え方が適用できる。例えば，3次正方行列の行列式は，列ベクトルが作る平行6面体（parallelepiped）の符号付き体積と一致する（図4.2）。 図 4.2: 列ベクトルが成す平行六面体 このことから分かることは，行列を構成する列に同じ向きを持つ（平行な）ベクトルが含まれていると行列式は必ずゼロになるということである。 図 4.3: 平行な列ベクトル 2本のベクトル\\(v_1 \\neq 0 \\neq v_2\\) が面積を持つ平行四辺形を作るための必要十分条件は， \\(v_1 = \\alpha v_2\\) となるような, \\(\\alpha \\neq 0\\) が存在しないことである（図4.3）。 ゼロと異なる3本のベクトル \\(v_1, v_2, v_3\\) が体積を持つ平行六面体を作るための必要十分条件は， \\(v_1 = \\alpha v_2 + \\beta v_3\\) かつ \\(\\alpha\\) と \\(\\beta\\) は同時にはゼロでないというものである。 いずれかのベクトルがゼロである可能性も考慮して，次のような概念を定義すると便利である。 定義 4.1 \\(n\\) 本のベクトル \\(v_1, \\dots, v_n\\) が1次独立（linearly independent）であるとは, \\(\\alpha_{1},\\dots,\\alpha_{n}\\) に対して \\(\\alpha_{1}v_{1}+ \\cdots + \\alpha_{n}v_{n}=0\\) が成り立てば，\\(\\alpha_{1}=\\cdots=\\alpha_{n}=0\\) が成り立つことをいう。 1次独立でないとき，ベクトルの組は 1次従属（linearly dependent）であるという。 行列を構成する列ベクトルが1次独立でなければ，列基本変形によりゼロのみからなる列を構成することができる。したがって，そのような行列の行列式はゼロでなければならない。逆に，行列が1次独立な列をもつならば（後に示すように），その行列はフルランクである。したがって，行列式はゼロでない。 これから先，正方行列の正則性は列ベクトルの1次独立性，行列式がゼロでないこと，行列のランクが次数と一致することなど同値な条件が形を変えて繰り返し現れることになる。これらの関係を理解しておくと動学理論を見通しよく習得できる。 4.2 固有値と固有ベクトル 複素数 \\(\\lambda\\) が正方行列 \\(A\\in\\mathbb{F}^{n\\times n}\\) の固有値 (eigenvalue) であるとは，ゼロでない列ベクトル \\(v\\in\\mathbb{C}^{n}\\) が存在して \\[ Av=\\lambda v \\] が成り立つことをいう。ベクトル \\(v\\) を固有値 \\(\\lambda\\) に対応する固有ベクトル (eigenvector) という。 一般に，行列を掛けるとベクトルの向きを回転させるのだが，固有ベクトルに対してだけは向きを変えないか， あるいは \\(\\lambda\\) が負であればベクトルの矢印を反転させる。 固有ベクトルという言葉は，1つの固有値に対して1つの固有ベクトルがあるというような印象を与えるかもしれない。 しかし，\\(v\\) が固有ベクトルであれば，\\(2v\\) も \\(-3v\\) も固有ベクトルであることが容易に確かめられる。 あるいは，1つの固有値に対して，1次独立な \\(v, w\\) という2つの固有ベクトルが見つかることもある。 このとき \\(v + w\\) も \\(-v + 3w\\) も同じ固有値に対する固有ベクトルである。 固有ベクトルを特定の性質を持つベクトルの集合（固有空間 eigenspace）から任意に1つ選んだものと認識しておくとよい。 方程式\\(Av=\\lambda v\\)の自明な変形により \\[ (\\lambda I-A)v=0 \\] が得られる。この方程式がゼロでないベクトルを解に持つための必要十分条件は \\[ \\phi_{A}(\\lambda)=\\det(\\lambda I-A)=0 \\] が成り立つことである。 上の事実を確認せよ。[ヒント：正則性と行列式の関係を使う。] \\(\\phi_{A}(\\lambda)\\) は \\(\\lambda\\) に関する \\(n\\) 次多項式であり, 固有多項式 (characteristic polynomial) という。\\(\\phi_{A}(\\lambda)=0\\) は重複度を込めて\\(n\\) 個の解を持つので，\\(A\\) は (重複度を込めて) \\(n\\) 個の固有値を持つ18。 固有多項式の係数を \\[ \\phi_{A}(\\lambda)=\\lambda^{n}+c_{1}\\lambda^{n-1}+\\cdots+c_{n} \\] とすれば， \\[ c_{1}=-\\operatorname{trace} A,\\qquad c_{n}=(-1)^{n}\\det A \\] が成り立つことを示せ。 なお，\\(\\operatorname{trace} A = \\sum_{i=1}^n A_{i,i}\\) は行列 \\(A\\) のトレースといい， 対角成分を足して得られる数である。 定理 4.1 実行列 \\(A\\in\\mathbb{R}^{n\\times n}\\)が複素固有値 \\(\\lambda\\) を持てば，\\(\\bar{\\lambda}\\) も\\(A\\) の固有値である。 定理4.1を証明せよ。 定理 4.2 異なる固有値 \\(\\lambda_{1}\\neq\\lambda_{2}\\) に対する固有ベクトル \\(v_{1}\\)，\\(v_{2}\\) は1次独立である。すなわち \\(\\alpha_{1},\\alpha_{2}\\in\\mathbb{C}\\) に対して， \\[ \\alpha_{1}v_{1}+\\alpha_{2}v_{2}=0\\Rightarrow\\alpha_{1}=\\alpha_{2}=0. \\] 証明. 定理の主張に反して1次従属であったとしよう。すなわち，同時にはゼロでない \\(\\alpha_{1}, \\alpha_{2}\\) があって\\(\\alpha_{1}v_{1}+\\alpha_{2}v_{2}=0\\)を満たすとする。 一般性を失うことなく，\\(\\alpha_1 \\neq 0\\) とできる。 このとき， \\[ \\alpha_{1}Av_{1}+\\alpha_{2}Av_{2}=0. \\] 固有値の定義より \\[ \\alpha_{1}\\lambda_{1}v_{1}+\\alpha_{2}\\lambda_{2}v_{2}=0. \\] \\(\\lambda_{1}\\neq\\lambda_{2}\\) より，一方はゼロでない。一般性を失うことなく\\(\\lambda_{1}\\neq0\\) とできて, \\[ \\alpha_{1}v_{1}+(\\lambda_{2}/\\lambda_{1})\\alpha_{2}v_{2}=0. \\] \\(\\alpha_1 v_1 + \\alpha_2 v_2 = 0\\) より, \\[ \\left[ 1 - (\\lambda_{2}/\\lambda_{1}) \\right] \\alpha_{1}v_{1}=0. \\] \\(\\alpha_{1}\\neq0\\)，\\(v_{1}\\neq0\\) なので，\\(\\lambda_{2}/\\lambda_{1}=1\\) が成り立たなければならないが, これは異なる固有値を選んだという前提に矛盾する 従って，相異なる固有値に対応する固有ベクトルは1次独立でなければならない。 2つ以上の異なる固有値についても同様のことが証明できる。 定理 4.3 正方行列 \\(A \\in \\mathbb R^{n \\times n}\\) が相異なる固有値 \\(\\lambda_{1}, \\dots, \\lambda_{n}\\) をもつとする。それぞれの固有値 \\(\\lambda_i\\) に対応する固有ベクトル \\(v_i\\) としたとき， \\(\\{ v_1, \\dots, v_n \\}\\) は1次独立である。 すなわち， \\(\\alpha_{1},\\dots,\\alpha_{n}\\in\\mathbb{C}\\) に対して \\(\\alpha_{1}v_{1}+ \\cdots + \\alpha_{n}v_{n}=0\\) が成り立てば，\\(\\alpha_{1}=\\cdots=\\alpha_{n}=0\\) が成り立つ。 定理4.3を証明せよ。 4.3 対角化 4.3.1 計算方法の確認 対角化（diagonalization）というのは，行列の標準形（canonical form）の中でももっとも基本的なものであるから， きちんと理解して使えるようになってほしい。 理論的な解説は次章以降に譲って，ここでは計算方法を思い出してもらおう。 簡単のため，行列 \\(A \\in \\mathbb R^{n \\times n}\\) の固有値\\(\\lambda_1,\\dots, \\lambda_n \\in \\mathbb C\\) が互いに異なると仮定する。対応する固有ベクトルをそれぞれ \\(v_1,\\dots, v_n \\in \\mathbb C^n\\) とすれば， \\[ Av_1 = \\lambda_1 v_1, \\dots, Av_n = \\lambda_n v_n \\] が成り立つ。\\(v_1, \\dots, v_n\\) を並べた行列 \\[ V = \\begin{bmatrix} v_1 &amp; \\cdots &amp; v_n \\end{bmatrix} \\] を定義すれば， \\[ \\begin{aligned} AV &amp;= \\begin{bmatrix} Av_1 &amp; \\cdots &amp; Av_n \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} \\lambda_1 v_1 &amp; \\cdots &amp; \\lambda_n v_n \\end{bmatrix}\\\\ &amp;= \\begin{bmatrix} v_1 &amp; \\cdots &amp; v_n \\end{bmatrix} \\begin{bmatrix} \\lambda_1 &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\lambda_n \\end{bmatrix} \\\\ &amp;= VD \\end{aligned} \\] が成り立つ。ただし， \\[ D = \\begin{bmatrix} \\lambda_1 &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\lambda_n \\end{bmatrix} \\] とおいた。 もとの行列と対角化行列を行き来するために，固有ベクトルを並べた行列\\(V\\) が重要な役割を果たす。 実際，定理4.3 によって\\(V\\)が正則であることが分かる。\\(V^{-1}\\)が存在するので， \\[ A = VDV^{-1}, \\qquad D = V^{-1}AV \\] という公式を得る。 4.3.2 例題 行列 \\[ J = \\begin{bmatrix} 0 &amp; -1\\\\ 1 &amp; 0 \\end{bmatrix} \\] の固有値と固有ベクトルを計算してみよう。 \\[ \\det(\\lambda J-I) = \\left| \\begin{bmatrix} \\lambda &amp; 1\\\\ -1 &amp; \\lambda \\end{bmatrix} \\right| = \\lambda^2 + 1 \\] だから，固有値は \\(\\pm i\\) である。固有値 \\(i\\) に対する固有ベクトルは， \\[ \\begin{bmatrix} 0 &amp; -1\\\\ 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = i \\begin{bmatrix} x\\\\ y \\end{bmatrix} \\] の解であり， \\[ x = iy \\] によって特徴付けられる。例えば， \\[ v_i = \\begin{bmatrix}i\\\\1\\end{bmatrix} \\] が固有ベクトルである。固有値 \\(- i\\) に対する固有ベクトルは， \\[ \\begin{bmatrix} 0 &amp; -1\\\\ 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = - i \\begin{bmatrix} x\\\\y \\end{bmatrix} \\] の解であり， \\[ ix=y \\] によって特徴付けられる。例えば， \\[ v_{-i}=\\begin{bmatrix} 1\\\\ i \\end{bmatrix} \\] が固有ベクトルである。 固有ベクトル\\(v_{i}\\) と \\(v_{-i}\\)を並べた行列 \\[ V = \\begin{bmatrix} v_{j} &amp; v_{-j} \\end{bmatrix} = \\begin{bmatrix} i &amp; 1\\\\ 1 &amp; i \\end{bmatrix} \\] は正則であり（\\(\\det V = i^2 - 1 = -2\\)）， \\[ V^{-1} = \\frac{1}{i^2-1} \\begin{bmatrix} i &amp; -1\\\\ -1 &amp; i \\end{bmatrix} = \\begin{bmatrix} -i/2 &amp; 1/2\\\\ 1/2 &amp; -i/2 \\end{bmatrix}. \\] \\[ \\begin{aligned} V\\begin{bmatrix} i &amp; 0\\\\ 0 &amp; -i \\end{bmatrix}V^{-1} &amp; = \\begin{bmatrix} i &amp; 1\\\\ 1 &amp; i \\end{bmatrix}\\begin{bmatrix} i &amp; 0\\\\ 0 &amp; -i \\end{bmatrix}\\begin{bmatrix} -i/2 &amp; 1/2\\\\ 1/2 &amp; -i/2 \\end{bmatrix}\\\\ &amp; = \\begin{bmatrix} -1 &amp; -i\\\\ i &amp; 1 \\end{bmatrix}\\begin{bmatrix} -i/2 &amp; 1/2\\\\ 1/2 &amp; -i/2 \\end{bmatrix}\\\\ &amp; = \\begin{bmatrix} 0 &amp; -1\\\\ 1 &amp; 0 \\end{bmatrix}\\\\ &amp; = J. \\end{aligned} \\] あるいは \\begin{equation} \\begin{bmatrix} i &amp; 0\\\\ 0 &amp; -i \\end{bmatrix} = V^{-1}JV (\\#eq:J-matrix) \\end{equation} が成り立つ。固有ベクトルを並べた行列\\(V\\)によって \\(J\\) を対角行列に変形 (対角化) することができた。 あらゆる行列に対してこのような変形ができる訳ではないことには注意が必要である。 すべての固有値が相異なる場合や，対称行列などが対角化が可能である。 4.3.3 複素数の行列表現 行列 \\[ J = \\begin{bmatrix} 0 &amp; -1\\\\ 1 &amp; 0 \\end{bmatrix} \\] に対して \\[ J^{2}=-I \\] が成り立つことに注意しよう。\\(I\\) を実数の単位（すなわち，\\(1\\)）と対応させれば， \\(J\\) が虚数単位と同じ性質を持つことが想像できるだろう。複素数 \\(z = a + bi\\) を行列を用いて \\[ Z = aI+bJ = \\begin{bmatrix} a &amp; -b\\\\ b &amp; a \\end{bmatrix} \\] と表すことができる。これをさらに極形式 \\(z = re^{i \\theta} = r\\cos \\theta + i(r \\sin \\theta)\\)， \\(r \\ge 0, 0 \\le \\theta &lt; 2\\pi\\) の記号を用いて書き直せば， \\[ Z=r\\begin{bmatrix} \\cos\\theta &amp; -\\sin\\theta\\\\ \\sin\\theta &amp; \\cos\\theta \\end{bmatrix} \\] とできる。 \\[ Z^n \\begin{bmatrix} x_{1}\\\\ x_{2} \\end{bmatrix} = r^n \\begin{bmatrix} \\cos n\\theta &amp; -\\sin n\\theta\\\\ \\sin n\\theta &amp; \\cos n\\theta \\end{bmatrix} \\begin{bmatrix} x_{1}\\\\ x_{2} \\end{bmatrix} \\] をR上で計算し，\\(Z\\) がベクトルの伸縮と回転という複素数積と同様の性質を持っていることを確認しておこう。 r = 0.8; theta = pi / 6 # polar form Z = r * matrix(c(cos(theta), -sin(theta), sin(theta), cos(theta)), nrow=2, byrow=TRUE) v0 = c(1, 0) # initial vector # iterative multiplication simulation_size = 50 # &gt;= 2 res = tibble(x1 = numeric(simulation_size), x2 = numeric(simulation_size)) res$x1[1] = v0[1]; res$x2[1] = v0[2] for (i in 2:simulation_size) { v1 = Z %*% v0 res$x1[i] = v1[1]; res$x2[i] = v1[2] v0 = v1 } # plot ggplot(res, aes(x1, x2)) + geom_point() 4.3.4 実対角化 複素数を実係数の行列で表現できるという考え方は，実係数の範囲で行列を標準化（ブロック対角化, 実ジョルダン標準化）する場合などに役に立つ。一般に固有値・固有ベクトルは複素数・複素ベクトルであるが，考えたいモデルの自然な表現が実数である場合には，実標準形の方が望ましいというケースもあるだろう。また，Klein (2000) が議論しているように，実標準形を用いる方が数値計算を高速に実行できるケースもある。 本書では複素数の範囲で標準化を考えるが，基本的な方針だけを述べておこう。 例えば，2次正方行列\\(A \\in \\mathbb R^2\\) が対角化の手続きによって， \\[ AP = P \\begin{bmatrix} a + bi &amp; 0 \\\\ 0 &amp; a - bi \\end{bmatrix} \\] と対角化できたとしよう。 定理4.1より共役複素数が必ずペアで現れることに注意せよ。 \\(P\\) は固有ベクトルを並べた行列である。式(??)より， \\[ \\begin{aligned} AP &amp;= P \\left( a I + b \\begin{bmatrix} i &amp; 0 \\\\ 0 &amp; - i \\end{bmatrix} \\right) \\\\ &amp;= P(aV^{-1}IV + b V^{-1} J V)\\\\ &amp;= PV^{-1} (aI + bJ) V \\end{aligned} \\] したがって， \\[ A(PV^{-1}) = (PV^{-1})(aI + bJ) \\] あるいは， \\[ A = (PV^{-1})(aI + bJ)(PV^{-1})^{-1} \\] とできる。これが\\(A\\)の実行列の範囲での標準化（real canonical form）の基本である。 2次より大きい行列の場合には， 現れる複素数の数だけ \\(aI + bJ\\) の形式のブロックが対角成分に並ぶ。 実対角化の結果は，例えば次のようなブロック対角行列になる。 \\[ \\begin{bmatrix} a_1 &amp; -b_1 &amp; &amp; &amp; &amp; \\\\ b_1 &amp; a_1 &amp; &amp; &amp; &amp; \\\\ &amp; &amp; a_2 &amp; -b_2 &amp; &amp; \\\\ &amp; &amp; b_2 &amp; a_2 &amp; &amp; \\\\ &amp; &amp; &amp; &amp;\\ddots &amp; \\\\ &amp; &amp; &amp; &amp; &amp; \\ddots \\end{bmatrix} \\] 4.4 線形動学方程式と固有値 再び，線形動学方程式 \\[ x_{t+1} = Ax_t \\] を考えよう。行列 \\(A\\) が \\(AV = VD\\) によって対角化されたとすると， $y_t = \\[ x_{t+1} = AVV^{-1}x_t = VDV^{-1} x_t. \\] \\(y = V^{-1}x\\) と定義すれば， \\[ y_{t+1} = Dy_t \\] とできる。\\(y_t = D^t y_0\\) は容易に計算することができる。実際， \\[ D = \\begin{bmatrix} \\lambda_1 &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\lambda_n \\end{bmatrix} \\] とすれば， \\[ D^t = \\begin{bmatrix} \\lambda_1^t &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\lambda_n^t \\end{bmatrix}, \\qquad t = 0,1,\\dots \\] が成り立つ。\\(A^t = (VDV^{-1})^t= VD^tV^{-1}\\) により, 固有値を用いて\\(x_t\\) の振る舞いを分析できる。 固有値がすべて複素平面上の単位円の内側にあれば，原点は大域的に漸近安定である。 線形システムは安定であり，任意の初期値 \\(x_0\\) に対して \\(\\lim_{t\\to\\infty} x_t \\to 0\\) が成り立つ。すべての固有値が単位円の外側にあれば， 任意の初期値\\(x_0 \\neq 0\\) に対して，\\(x_t\\) は発散する。すなわち，\\(\\| x_t \\| \\to \\infty\\) が成り立つ19。 このような挙動を指してシステムが反安定 antistableであると呼ぼう。 絶対値が1より小さい固有値を安定固有値（stable eigenvalue）, 1より大きい固有値を不安定固有値（unstable eigenvalue）と呼ぶ。 （ただし，この呼び方は離散時間システムを考えている限りにおいてのみ意味がある。 連続時間システムでは別の条件によって安定性が特徴付けられる。） 経済学においては，固有値のいくつかが安定であり， 残りが不安定であるというのが典型的である。このような原点を鞍点（saddle）， システムの鞍点周りの挙動を鞍点安定（saddle-point stability）と呼んでいる。 力学系の理論では，通常，不安定性の一種として扱われることが多いのだが， 経済学ではすべての初期条件が与えられていない問題を考えるという事情によって 鞍点安定なシステムにおける収束経路に重要な解釈を与えている。 すなわち，発散する経路ではなく原点に収束していく経路が経済主体の意思決定によって選ばれるのである。これを仮定することもあれば，モデルの解が満たす条件として得られるケースもある。 実際には反安定となるケースもあるにはあるのだが，鞍点の方が発生しやすい。 ラムゼーモデルを通して観察してみよう。 4.5 ラムゼーモデルと固有値 再びラムゼーモデルの不動点を考えよう。Levhari and Liviatan (1972) によれば，\\(\\lambda\\) が固有値であれば，\\(1/(\\beta \\lambda)\\) も固有値である。したがって， ラムゼーモデルの不動点の固有値は複素平面上で原点を中心とする半径\\(1/\\beta\\) の円を挟むように分布する。 1セクターモデルではいずれも実数になるから，図4.4 あるいは， 図4.5 といったケースが典型的である。 図 4.4: 鞍点（1セクター） 図 4.5: 不安定（1セクター） 一般のセクターに対しては定理2.3 は成り立たない。 複素固有値 \\(\\lambda\\) が存在すれば，定理4.1 によって\\(\\bar \\lambda\\) も固有値である。さらに，Levhari and Liviatan (1972) によれば \\(1/(\\beta \\lambda)\\) と \\(1/(\\beta \\bar \\lambda)\\)も固有値である。1つの複素固有値から3つの複素固有値が派生する。図??, 図4.7。 図 4.6: 鞍点（マルチセクター） 図 4.7: 不安定（マルチセクター） 不動点は鞍点であるか，あるいは反安定となる。図から想像できるように， \\(\\beta\\) が1に近づくにつれて，安定な固有値が生じて鞍点になりやすい。 実は\\(\\beta\\) が十分1に近いとき，ラムゼーモデルは大域的に安定な経路を持つことが知られている。 大域的安定性の研究はターンパイク（turnpike）理論と呼ばれる一大分野を形成している。(McKenzie 1986) 逆に，\\(\\beta\\)が小さくなると安定性が失われ，不安定挙動（周期軌道，カオス）が現れる。 例えば Deneckere and Pelikan (1986) を見よ。 参考文献 "],
["e58f82e88083e69687e78cae.html", "参考文献", " 参考文献 "]
]
